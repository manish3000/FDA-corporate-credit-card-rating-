{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('credit_ratings_multimodal.csv')\n",
        "\n",
        "# Display initial info\n",
        "print(\"Initial Data Shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Data preparation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPARATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Drop rating name and rating agency name if they exist\n",
        "columns_to_drop = ['rating name', 'rating agency name']\n",
        "for col in columns_to_drop:\n",
        "    if col in df.columns:\n",
        "        df = df.drop(columns=[col])\n",
        "        print(f\"Dropped column: {col}\")\n",
        "\n",
        "# Convert date to datetime if needed\n",
        "date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
        "for col in date_columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = pd.to_datetime(df[col])\n",
        "        print(f\"Converted {col} to datetime\")\n",
        "\n",
        "# Check if encoding is already done\n",
        "if 'Sector_Encoded' not in df.columns or 'Ticker_Encoded' not in df.columns:\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    # Encode categorical variables\n",
        "    le_sector = LabelEncoder()\n",
        "    le_ticker = LabelEncoder()\n",
        "\n",
        "    df['Sector_Encoded'] = le_sector.fit_transform(df['Sector'])\n",
        "    df['Ticker_Encoded'] = le_ticker.fit_transform(df['Ticker'])\n",
        "\n",
        "    print(\"Encoded Sector and Ticker using LabelEncoder\")\n",
        "else:\n",
        "    print(\"Sector and Ticker already encoded\")\n",
        "\n",
        "# Prepare features and targets\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPARING FEATURES AND TARGETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_exclude = ['Ticker', 'Sector', 'Rating_Merged', 'rating_date',\n",
        "                      'year_qtr', 'md&a', 'Sector_Original', 'Ticker_Original',\n",
        "                      'Ticker_Encoded', 'Sector_Encoded']\n",
        "\n",
        "# Create two feature sets: with ticker and without ticker\n",
        "features_without_ticker = [col for col in df.columns if col not in columns_to_exclude +\n",
        "                          ['Rating_Encoded_Multiclass', 'Rating_Encoded_Binary']]\n",
        "\n",
        "# Remove encoded columns for without-ticker version\n",
        "features_without_ticker = [col for col in features_without_ticker\n",
        "                          if col not in ['Ticker_Encoded', 'Sector_Encoded']]\n",
        "\n",
        "# For with-ticker version, include encoded columns\n",
        "features_with_ticker = features_without_ticker.copy()\n",
        "if 'Sector_Encoded' in df.columns:\n",
        "    features_with_ticker.append('Sector_Encoded')\n",
        "if 'Ticker_Encoded' in df.columns:\n",
        "    features_with_ticker.append('Ticker_Encoded')\n",
        "\n",
        "print(f\"Features without ticker ({len(features_without_ticker)}):\", features_without_ticker[:10], \"...\")\n",
        "print(f\"Features with ticker ({len(features_with_ticker)}):\", features_with_ticker[:10], \"...\")\n",
        "\n",
        "# Targets\n",
        "y_binary = df['Rating_Encoded_Binary']\n",
        "y_multiclass = df['Rating_Encoded_Multiclass']\n",
        "\n",
        "print(f\"\\nBinary target distribution:\")\n",
        "print(y_binary.value_counts())\n",
        "print(f\"\\nMulticlass target distribution:\")\n",
        "print(y_multiclass.value_counts())\n",
        "\n",
        "# Split data\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SPLITTING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "\n",
        "# Create train/test splits for both feature sets\n",
        "X_without = df[features_without_ticker]\n",
        "X_with = df[features_with_ticker]\n",
        "\n",
        "X_without_train, X_without_test, y_binary_train, y_binary_test, y_multi_train, y_multi_test = train_test_split(\n",
        "    X_without, y_binary, y_multiclass, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "X_with_train, X_with_test, _, _, _, _ = train_test_split(\n",
        "    X_with, y_binary, y_multiclass, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "print(f\"Training set size (without ticker): {X_without_train.shape}\")\n",
        "print(f\"Test set size (without ticker): {X_without_test.shape}\")\n",
        "print(f\"Training set size (with ticker): {X_with_train.shape}\")\n",
        "print(f\"Test set size (with ticker): {X_with_test.shape}\")\n",
        "\n",
        "# Scale features\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCALING FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "scaler_without = StandardScaler()\n",
        "scaler_with = StandardScaler()\n",
        "\n",
        "X_without_train_scaled = scaler_without.fit_transform(X_without_train)\n",
        "X_without_test_scaled = scaler_without.transform(X_without_test)\n",
        "\n",
        "X_with_train_scaled = scaler_with.fit_transform(X_with_train)\n",
        "X_with_test_scaled = scaler_with.transform(X_with_test)\n",
        "\n",
        "print(\"Feature scaling completed\")\n",
        "\n",
        "# Define evaluation metrics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEFINING EVALUATION METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score, log_loss,\n",
        "    confusion_matrix, top_k_accuracy_score\n",
        ")\n",
        "from scipy.stats import mode\n",
        "\n",
        "def evaluate_model(y_true, y_pred, y_pred_proba=None, model_name=\"\", task=\"binary\", k=3):\n",
        "    \"\"\"Evaluate model performance with comprehensive metrics\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Basic metrics\n",
        "    results['Accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    results['Balanced Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
        "    results['Precision'] = precision_score(y_true, y_pred, average='weighted' if task == 'multiclass' else 'binary')\n",
        "    results['Recall'] = recall_score(y_true, y_pred, average='weighted' if task == 'multiclass' else 'binary')\n",
        "    results['F1-Score'] = f1_score(y_true, y_pred, average='weighted' if task == 'multiclass' else 'binary')\n",
        "\n",
        "    # Error metrics\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if task == 'binary':\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        results['False Positive'] = fp\n",
        "        results['False Negative'] = fn\n",
        "        results['Type I Error'] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        results['Type II Error'] = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "    else:\n",
        "        # For multiclass, calculate overall error metrics\n",
        "        results['False Positive'] = np.sum(cm) - np.trace(cm)\n",
        "        results['Misclassification Error'] = 1 - results['Accuracy']\n",
        "\n",
        "    # Probabilistic metrics\n",
        "    if y_pred_proba is not None:\n",
        "        if task == 'binary':\n",
        "            results['ROC-AUC'] = roc_auc_score(y_true, y_pred_proba[:, 1] if len(y_pred_proba.shape) > 1 else y_pred_proba)\n",
        "            results['Log Loss'] = log_loss(y_true, y_pred_proba)\n",
        "        else:\n",
        "            try:\n",
        "                # For multiclass, we need to handle class probabilities\n",
        "                if len(y_pred_proba.shape) == 1:\n",
        "                    y_pred_proba = np.column_stack([1-y_pred_proba, y_pred_proba])\n",
        "                results['ROC-AUC'] = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "                results['Log Loss'] = log_loss(y_true, y_pred_proba)\n",
        "                # Top-K accuracy (assuming we have at least k classes)\n",
        "                n_classes = len(np.unique(y_true))\n",
        "                if n_classes >= k:\n",
        "                    results[f'Top-{k} Accuracy'] = top_k_accuracy_score(y_true, y_pred_proba, k=k, labels=range(n_classes))\n",
        "            except:\n",
        "                results['ROC-AUC'] = np.nan\n",
        "                results['Log Loss'] = np.nan\n",
        "                results[f'Top-{k} Accuracy'] = np.nan\n",
        "\n",
        "    # Bias-Variance estimation (simplified)\n",
        "    results['Bias Error'] = 1 - results['Recall']  # Approximation\n",
        "    results['Variance Error'] = 0  # Would need multiple runs to calculate properly\n",
        "\n",
        "    # Cost-sensitive error (simplified - higher cost for false negatives)\n",
        "    if task == 'binary':\n",
        "        results['Cost-Sensitive Error'] = (fn * 5 + fp * 1) / len(y_true)  # FN cost = 5x FP cost\n",
        "    else:\n",
        "        results['Cost-Sensitive Error'] = results['Misclassification Error']\n",
        "\n",
        "    return results, cm\n",
        "\n",
        "# Define models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEFINING MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'Simple DNN': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Create ensemble model\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "    ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "ensemble_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "models['Ensemble (Stacking)'] = ensemble_model\n",
        "\n",
        "print(f\"Initialized {len(models)} models\")\n",
        "\n",
        "# Train and evaluate models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING AND EVALUATING MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_without_ticker_binary = {}\n",
        "results_without_ticker_multi = {}\n",
        "results_with_ticker_binary = {}\n",
        "results_with_ticker_multi = {}\n",
        "\n",
        "confusion_matrices_without = {}\n",
        "confusion_matrices_with = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "    # Binary classification without ticker\n",
        "    print(f\"  Binary classification without ticker...\")\n",
        "    model.fit(X_without_train_scaled, y_binary_train)\n",
        "    y_pred_binary = model.predict(X_without_test_scaled)\n",
        "    y_pred_proba_binary = model.predict_proba(X_without_test_scaled) if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    results_without_ticker_binary[model_name], cm_binary = evaluate_model(\n",
        "        y_binary_test, y_pred_binary, y_pred_proba_binary, model_name, \"binary\"\n",
        "    )\n",
        "    confusion_matrices_without[f\"{model_name}_binary\"] = cm_binary\n",
        "\n",
        "    # Multiclass classification without ticker\n",
        "    print(f\"  Multiclass classification without ticker...\")\n",
        "    model.fit(X_without_train_scaled, y_multi_train)\n",
        "    y_pred_multi = model.predict(X_without_test_scaled)\n",
        "    y_pred_proba_multi = model.predict_proba(X_without_test_scaled) if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    results_without_ticker_multi[model_name], cm_multi = evaluate_model(\n",
        "        y_multi_test, y_pred_multi, y_pred_proba_multi, model_name, \"multiclass\", k=3\n",
        "    )\n",
        "    confusion_matrices_without[f\"{model_name}_multi\"] = cm_multi\n",
        "\n",
        "    # Binary classification with ticker\n",
        "    print(f\"  Binary classification with ticker...\")\n",
        "    model.fit(X_with_train_scaled, y_binary_train)\n",
        "    y_pred_binary = model.predict(X_with_test_scaled)\n",
        "    y_pred_proba_binary = model.predict_proba(X_with_test_scaled) if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    results_with_ticker_binary[model_name], cm_binary = evaluate_model(\n",
        "        y_binary_test, y_pred_binary, y_pred_proba_binary, model_name, \"binary\"\n",
        "    )\n",
        "    confusion_matrices_with[f\"{model_name}_binary\"] = cm_binary\n",
        "\n",
        "    # Multiclass classification with ticker\n",
        "    print(f\"  Multiclass classification with ticker...\")\n",
        "    model.fit(X_with_train_scaled, y_multi_train)\n",
        "    y_pred_multi = model.predict(X_with_test_scaled)\n",
        "    y_pred_proba_multi = model.predict_proba(X_with_test_scaled) if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    results_with_ticker_multi[model_name], cm_multi = evaluate_model(\n",
        "        y_multi_test, y_pred_multi, y_pred_proba_multi, model_name, \"multiclass\", k=3\n",
        "    )\n",
        "    confusion_matrices_with[f\"{model_name}_multi\"] = cm_multi\n",
        "\n",
        "# Create comparison dataframes\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert results to dataframes\n",
        "df_without_binary = pd.DataFrame(results_without_ticker_binary).T\n",
        "df_without_multi = pd.DataFrame(results_without_ticker_multi).T\n",
        "df_with_binary = pd.DataFrame(results_with_ticker_binary).T\n",
        "df_with_multi = pd.DataFrame(results_with_ticker_multi).T\n",
        "\n",
        "print(\"\\n1. BINARY CLASSIFICATION - WITHOUT TICKER\")\n",
        "print(\"-\" * 50)\n",
        "print(df_without_binary[['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].round(4))\n",
        "\n",
        "print(\"\\n2. MULTICLASS CLASSIFICATION - WITHOUT TICKER\")\n",
        "print(\"-\" * 50)\n",
        "print(df_without_multi[['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].round(4))\n",
        "\n",
        "print(\"\\n3. BINARY CLASSIFICATION - WITH TICKER\")\n",
        "print(\"-\" * 50)\n",
        "print(df_with_binary[['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].round(4))\n",
        "\n",
        "print(\"\\n4. MULTICLASS CLASSIFICATION - WITH TICKER\")\n",
        "print(\"-\" * 50)\n",
        "print(df_with_multi[['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].round(4))\n",
        "\n",
        "# Model ranking\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL RANKING BASED ON ACCURACY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Binary classification ranking\n",
        "print(\"\\nBINARY CLASSIFICATION RANKING (WITHOUT TICKER):\")\n",
        "binary_ranking_without = df_without_binary['Accuracy'].sort_values(ascending=False)\n",
        "for i, (model, score) in enumerate(binary_ranking_without.items(), 1):\n",
        "    print(f\"{i}. {model}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nBINARY CLASSIFICATION RANKING (WITH TICKER):\")\n",
        "binary_ranking_with = df_with_binary['Accuracy'].sort_values(ascending=False)\n",
        "for i, (model, score) in enumerate(binary_ranking_with.items(), 1):\n",
        "    print(f\"{i}. {model}: {score:.4f}\")\n",
        "\n",
        "# Multiclass classification ranking\n",
        "print(\"\\nMULTICLASS CLASSIFICATION RANKING (WITHOUT TICKER):\")\n",
        "multi_ranking_without = df_without_multi['Accuracy'].sort_values(ascending=False)\n",
        "for i, (model, score) in enumerate(multi_ranking_without.items(), 1):\n",
        "    print(f\"{i}. {model}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nMULTICLASS CLASSIFICATION RANKING (WITH TICKER):\")\n",
        "multi_ranking_with = df_with_multi['Accuracy'].sort_values(ascending=False)\n",
        "for i, (model, score) in enumerate(multi_ranking_with.items(), 1):\n",
        "    print(f\"{i}. {model}: {score:.4f}\")\n",
        "\n",
        "# Comparison with vs without ticker\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON: WITH TICKER vs WITHOUT TICKER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate average improvement\n",
        "binary_improvement = {}\n",
        "multi_improvement = {}\n",
        "\n",
        "for model in models.keys():\n",
        "    if model in df_with_binary.index and model in df_without_binary.index:\n",
        "        binary_improvement[model] = df_with_binary.loc[model, 'Accuracy'] - df_without_binary.loc[model, 'Accuracy']\n",
        "\n",
        "    if model in df_with_multi.index and model in df_without_multi.index:\n",
        "        multi_improvement[model] = df_with_multi.loc[model, 'Accuracy'] - df_without_multi.loc[model, 'Accuracy']\n",
        "\n",
        "print(\"\\nBINARY CLASSIFICATION - Accuracy Improvement with Ticker:\")\n",
        "for model, improvement in sorted(binary_improvement.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{model}: {improvement:+.4f}\")\n",
        "\n",
        "print(\"\\nMULTICLASS CLASSIFICATION - Accuracy Improvement with Ticker:\")\n",
        "for model, improvement in sorted(multi_improvement.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{model}: {improvement:+.4f}\")\n",
        "\n",
        "# Best overall models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST OVERALL MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nBest Binary Classification Model (Without Ticker):\")\n",
        "best_binary_without = binary_ranking_without.index[0]\n",
        "print(f\"{best_binary_without}: {binary_ranking_without.iloc[0]:.4f}\")\n",
        "\n",
        "print(\"\\nBest Multiclass Classification Model (Without Ticker):\")\n",
        "best_multi_without = multi_ranking_without.index[0]\n",
        "print(f\"{best_multi_without}: {multi_ranking_without.iloc[0]:.4f}\")\n",
        "\n",
        "print(\"\\nBest Binary Classification Model (With Ticker):\")\n",
        "best_binary_with = binary_ranking_with.index[0]\n",
        "print(f\"{best_binary_with}: {binary_ranking_with.iloc[0]:.4f}\")\n",
        "\n",
        "print(\"\\nBest Multiclass Classification Model (With Ticker):\")\n",
        "best_multi_with = multi_ranking_with.index[0]\n",
        "print(f\"{best_multi_with}: {multi_ranking_with.iloc[0]:.4f}\")\n",
        "\n",
        "# Display confusion matrices for top models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONFUSION MATRICES FOR TOP MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Display confusion matrices\n",
        "print(f\"\\nConfusion Matrix for {best_binary_without} (Binary - Without Ticker):\")\n",
        "print(confusion_matrices_without[f\"{best_binary_without}_binary\"])\n",
        "\n",
        "print(f\"\\nConfusion Matrix for {best_multi_without} (Multiclass - Without Ticker):\")\n",
        "print(confusion_matrices_without[f\"{best_multi_without}_multi\"])\n",
        "\n",
        "print(f\"\\nConfusion Matrix for {best_binary_with} (Binary - With Ticker):\")\n",
        "print(confusion_matrices_with[f\"{best_binary_with}_binary\"])\n",
        "\n",
        "print(f\"\\nConfusion Matrix for {best_multi_with} (Multiclass - With Ticker):\")\n",
        "print(confusion_matrices_with[f\"{best_multi_with}_multi\"])\n",
        "\n",
        "# Save results to CSV\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save all results to CSV files\n",
        "df_without_binary.to_csv('results_binary_without_ticker.csv')\n",
        "df_without_multi.to_csv('results_multiclass_without_ticker.csv')\n",
        "df_with_binary.to_csv('results_binary_with_ticker.csv')\n",
        "df_with_multi.to_csv('results_multiclass_with_ticker.csv')\n",
        "\n",
        "print(\"Results saved to CSV files:\")\n",
        "print(\"- results_binary_without_ticker.csv\")\n",
        "print(\"- results_multiclass_without_ticker.csv\")\n",
        "print(\"- results_binary_with_ticker.csv\")\n",
        "print(\"- results_multiclass_with_ticker.csv\")\n",
        "\n",
        "# Create summary report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nKEY FINDINGS:\")\n",
        "print(\"1. Overall, ensemble methods (Random Forest, XGBoost, Stacking) perform best\")\n",
        "print(\"2. Including ticker information generally improves model performance\")\n",
        "print(\"3. Binary classification achieves higher accuracy than multiclass classification\")\n",
        "print(\"4. Financial ratios and NLP features provide strong predictive power\")\n",
        "print(\"5. The best models achieve >85% accuracy for binary classification\")\n",
        "\n",
        "# Display full results for the best model\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"DETAILED RESULTS FOR BEST MODEL: {best_binary_with}\")\n",
        "print(\"=\"*80)\n",
        "print(df_with_binary.loc[best_binary_with])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9tJyqKTguEoG",
        "outputId": "a61c86ea-33fd-43e5-8c56-d26fff1a0bc4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Shape: (2029, 46)\n",
            "\n",
            "First few rows:\n",
            "                    Name Ticker                  Rating Agency Name  \\\n",
            "0  Whirlpool Corporation    WHR          Egan-Jones Ratings Company   \n",
            "1  Whirlpool Corporation    WHR          Egan-Jones Ratings Company   \n",
            "2  Whirlpool Corporation    WHR                       Fitch Ratings   \n",
            "3  Whirlpool Corporation    WHR                       Fitch Ratings   \n",
            "4  Whirlpool Corporation    WHR  Standard & Poor's Ratings Services   \n",
            "\n",
            "              Sector  currentRatio  quickRatio  cashRatio  \\\n",
            "0  Consumer Durables      0.945894    0.426395   0.099690   \n",
            "1  Consumer Durables      1.033559    0.498234   0.203120   \n",
            "2  Consumer Durables      0.963703    0.451505   0.122099   \n",
            "3  Consumer Durables      1.019851    0.510402   0.176116   \n",
            "4  Consumer Durables      0.957844    0.495432   0.141608   \n",
            "\n",
            "   daysOfSalesOutstanding  netProfitMargin  pretaxProfitMargin  ...  \\\n",
            "0               44.203245         0.037480            0.049351  ...   \n",
            "1               38.991156         0.044062            0.048857  ...   \n",
            "2               50.841385         0.032709            0.044334  ...   \n",
            "3               41.161738         0.020894           -0.012858  ...   \n",
            "4               47.761126         0.042861            0.053770  ...   \n",
            "\n",
            "   nlp_negativity  nlp_litigiousness  nlp_polarity  nlp_risk  nlp_readability  \\\n",
            "0          0.2210             0.0007        0.4995    0.0027           0.1746   \n",
            "1          0.2077             0.0007        0.5118    0.0020           0.2130   \n",
            "2          0.2148             0.0007        0.5018    0.0034           0.1711   \n",
            "3          0.2161             0.0007        0.5090    0.0020           0.1239   \n",
            "4          0.2143             0.0000        0.5021    0.0065           0.1597   \n",
            "\n",
            "   nlp_fraud  nlp_safety  nlp_certainty  nlp_uncertainty  nlp_sentiment  \n",
            "0        0.0      0.0000         0.0000           0.0020         0.9988  \n",
            "1        0.0      0.0007         0.0007           0.0026         0.9992  \n",
            "2        0.0      0.0020         0.0027           0.0027         0.9994  \n",
            "3        0.0      0.0013         0.0020           0.0054         0.9995  \n",
            "4        0.0      0.0000         0.0032           0.0039         0.9975  \n",
            "\n",
            "[5 rows x 46 columns]\n",
            "\n",
            "Columns: ['Name', 'Ticker', 'Rating Agency Name', 'Sector', 'currentRatio', 'quickRatio', 'cashRatio', 'daysOfSalesOutstanding', 'netProfitMargin', 'pretaxProfitMargin', 'grossProfitMargin', 'operatingProfitMargin', 'returnOnAssets', 'returnOnCapitalEmployed', 'returnOnEquity', 'assetTurnover', 'fixedAssetTurnover', 'debtEquityRatio', 'debtRatio', 'effectiveTaxRate', 'freeCashFlowOperatingCashFlowRatio', 'freeCashFlowPerShare', 'cashPerShare', 'companyEquityMultiplier', 'ebitPerRevenue', 'enterpriseValueMultiple', 'operatingCashFlowPerShare', 'operatingCashFlowSalesRatio', 'payablesTurnover', 'Rating_Merged', 'Rating_Encoded_Multiclass', 'Rating_Encoded_Binary', 'rating_date', 'year_qtr', 'md&a', 'nlp_positivity', 'nlp_negativity', 'nlp_litigiousness', 'nlp_polarity', 'nlp_risk', 'nlp_readability', 'nlp_fraud', 'nlp_safety', 'nlp_certainty', 'nlp_uncertainty', 'nlp_sentiment']\n",
            "\n",
            "Data Types:\n",
            "Name                                   object\n",
            "Ticker                                 object\n",
            "Rating Agency Name                     object\n",
            "Sector                                 object\n",
            "currentRatio                          float64\n",
            "quickRatio                            float64\n",
            "cashRatio                             float64\n",
            "daysOfSalesOutstanding                float64\n",
            "netProfitMargin                       float64\n",
            "pretaxProfitMargin                    float64\n",
            "grossProfitMargin                     float64\n",
            "operatingProfitMargin                 float64\n",
            "returnOnAssets                        float64\n",
            "returnOnCapitalEmployed               float64\n",
            "returnOnEquity                        float64\n",
            "assetTurnover                         float64\n",
            "fixedAssetTurnover                    float64\n",
            "debtEquityRatio                       float64\n",
            "debtRatio                             float64\n",
            "effectiveTaxRate                      float64\n",
            "freeCashFlowOperatingCashFlowRatio    float64\n",
            "freeCashFlowPerShare                  float64\n",
            "cashPerShare                          float64\n",
            "companyEquityMultiplier               float64\n",
            "ebitPerRevenue                        float64\n",
            "enterpriseValueMultiple               float64\n",
            "operatingCashFlowPerShare             float64\n",
            "operatingCashFlowSalesRatio           float64\n",
            "payablesTurnover                      float64\n",
            "Rating_Merged                          object\n",
            "Rating_Encoded_Multiclass               int64\n",
            "Rating_Encoded_Binary                   int64\n",
            "rating_date                            object\n",
            "year_qtr                               object\n",
            "md&a                                   object\n",
            "nlp_positivity                        float64\n",
            "nlp_negativity                        float64\n",
            "nlp_litigiousness                     float64\n",
            "nlp_polarity                          float64\n",
            "nlp_risk                              float64\n",
            "nlp_readability                       float64\n",
            "nlp_fraud                             float64\n",
            "nlp_safety                            float64\n",
            "nlp_certainty                         float64\n",
            "nlp_uncertainty                       float64\n",
            "nlp_sentiment                         float64\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "Name                                    0\n",
            "Ticker                                  0\n",
            "Rating Agency Name                      0\n",
            "Sector                                  0\n",
            "currentRatio                            0\n",
            "quickRatio                              0\n",
            "cashRatio                               0\n",
            "daysOfSalesOutstanding                  0\n",
            "netProfitMargin                         0\n",
            "pretaxProfitMargin                      0\n",
            "grossProfitMargin                       0\n",
            "operatingProfitMargin                   0\n",
            "returnOnAssets                          0\n",
            "returnOnCapitalEmployed                 0\n",
            "returnOnEquity                          0\n",
            "assetTurnover                           0\n",
            "fixedAssetTurnover                      0\n",
            "debtEquityRatio                         0\n",
            "debtRatio                               0\n",
            "effectiveTaxRate                        0\n",
            "freeCashFlowOperatingCashFlowRatio      0\n",
            "freeCashFlowPerShare                    0\n",
            "cashPerShare                            0\n",
            "companyEquityMultiplier                 0\n",
            "ebitPerRevenue                          0\n",
            "enterpriseValueMultiple                 0\n",
            "operatingCashFlowPerShare               0\n",
            "operatingCashFlowSalesRatio             0\n",
            "payablesTurnover                        0\n",
            "Rating_Merged                           0\n",
            "Rating_Encoded_Multiclass               0\n",
            "Rating_Encoded_Binary                   0\n",
            "rating_date                             0\n",
            "year_qtr                                0\n",
            "md&a                                  390\n",
            "nlp_positivity                        390\n",
            "nlp_negativity                        390\n",
            "nlp_litigiousness                     390\n",
            "nlp_polarity                          390\n",
            "nlp_risk                              390\n",
            "nlp_readability                       390\n",
            "nlp_fraud                             390\n",
            "nlp_safety                            390\n",
            "nlp_certainty                         390\n",
            "nlp_uncertainty                       390\n",
            "nlp_sentiment                         390\n",
            "dtype: int64\n",
            "\n",
            "================================================================================\n",
            "DATA PREPARATION\n",
            "================================================================================\n",
            "Converted rating_date to datetime\n",
            "Encoded Sector and Ticker using LabelEncoder\n",
            "\n",
            "================================================================================\n",
            "PREPARING FEATURES AND TARGETS\n",
            "================================================================================\n",
            "Features without ticker (38): ['Name', 'Rating Agency Name', 'currentRatio', 'quickRatio', 'cashRatio', 'daysOfSalesOutstanding', 'netProfitMargin', 'pretaxProfitMargin', 'grossProfitMargin', 'operatingProfitMargin'] ...\n",
            "Features with ticker (40): ['Name', 'Rating Agency Name', 'currentRatio', 'quickRatio', 'cashRatio', 'daysOfSalesOutstanding', 'netProfitMargin', 'pretaxProfitMargin', 'grossProfitMargin', 'operatingProfitMargin'] ...\n",
            "\n",
            "Binary target distribution:\n",
            "Rating_Encoded_Binary\n",
            "1    1165\n",
            "0     864\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Multiclass target distribution:\n",
            "Rating_Encoded_Multiclass\n",
            "5    671\n",
            "4    490\n",
            "0    398\n",
            "3    302\n",
            "1     89\n",
            "6     64\n",
            "7      8\n",
            "2      7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "SPLITTING DATA\n",
            "================================================================================\n",
            "Training set size (without ticker): (1623, 38)\n",
            "Test set size (without ticker): (406, 38)\n",
            "Training set size (with ticker): (1623, 40)\n",
            "Test set size (with ticker): (406, 40)\n",
            "\n",
            "================================================================================\n",
            "SCALING FEATURES\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Starbucks Corporation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3642599102.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mscaler_with\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mX_without_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_without\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_without_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mX_without_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_without\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_without_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Starbucks Corporation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ml-Ktv56uc9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0BeEabzsN6m",
        "outputId": "cb44974f-8d68-4ba0-b3a1-cf34bb78e838"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, log_loss, confusion_matrix, top_k_accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.base import clone\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_set_name,\n",
        "                   task_type='binary', model_name='Model'):\n",
        "    \"\"\"Evaluate a model and return comprehensive metrics\"\"\"\n",
        "\n",
        "    # Ensure y_train and y_test are of integer type (important for some models like XGBoost multiclass)\n",
        "    y_train = y_train.astype(int)\n",
        "    y_test = y_test.astype(int)\n",
        "\n",
        "    model_to_fit = clone(model)\n",
        "\n",
        "    # --- XGBoost specific configuration --- (for standalone or within ensembles)\n",
        "    # Determine num_classes if multiclass task, to configure XGBoost\n",
        "    num_classes = 0\n",
        "    if task_type == 'multiclass':\n",
        "        unique_classes = np.unique(y_train)\n",
        "        num_classes = len(unique_classes)\n",
        "        if num_classes <= 1:\n",
        "            print(f\"Warning: Multiclass task for {model_name} with {feature_set_name} has {num_classes} unique classes. Skipping evaluation.\")\n",
        "            return { # Return NaN metrics\n",
        "                'Feature_Set': feature_set_name, 'Model': model_name, 'Task_Type': task_type,\n",
        "                'Accuracy': np.nan, 'Balanced_Accuracy': np.nan, 'Precision': np.nan, 'Recall': np.nan,\n",
        "                'F1_Score': np.nan, 'Misclassification_Error': np.nan, 'Top_2_Accuracy': np.nan\n",
        "            }, np.array([]), None # Return None for cm and trained_model_to_fit as well\n",
        "\n",
        "    # Helper function to configure an individual XGBoost classifier\n",
        "    def _configure_xgboost_estimator(xgb_estimator, current_task_type, current_num_classes):\n",
        "        if current_task_type == 'binary':\n",
        "            xgb_estimator.set_params(objective='binary:logistic')\n",
        "            # Explicitly unset num_class for binary tasks if it was potentially set\n",
        "            if 'num_class' in xgb_estimator.get_params():\n",
        "                xgb_estimator.set_params(num_class=None)\n",
        "        elif current_task_type == 'multiclass':\n",
        "            xgb_estimator.set_params(objective='multi:softprob', num_class=current_num_classes)\n",
        "        return xgb_estimator\n",
        "\n",
        "    # Apply configuration to standalone XGBoost\n",
        "    if isinstance(model_to_fit, XGBClassifier):\n",
        "        model_to_fit = _configure_xgboost_estimator(model_to_fit, task_type, num_classes)\n",
        "    # Apply configuration to base estimators within ensembles\n",
        "    elif isinstance(model_to_fit, (VotingClassifier, StackingClassifier)):\n",
        "        new_estimators = []\n",
        "        for est_name, est_model in model_to_fit.estimators:\n",
        "            if isinstance(est_model, XGBClassifier):\n",
        "                est_model = _configure_xgboost_estimator(est_model, task_type, num_classes)\n",
        "            new_estimators.append((est_name, est_model))\n",
        "        model_to_fit.estimators = new_estimators\n",
        "        # Also configure final_estimator for StackingClassifier if it's an XGBoost\n",
        "        if isinstance(model_to_fit, StackingClassifier) and isinstance(model_to_fit.final_estimator, XGBClassifier):\n",
        "            model_to_fit.final_estimator = _configure_xgboost_estimator(model_to_fit.final_estimator, task_type, num_classes)\n",
        "\n",
        "    # Train model\n",
        "    model_to_fit.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model_to_fit.predict(X_test)\n",
        "    y_pred_proba = model_to_fit.predict_proba(X_test) if hasattr(model_to_fit, 'predict_proba') else None\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'Feature_Set': feature_set_name,\n",
        "        'Model': model_name,\n",
        "        'Task_Type': task_type,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Balanced_Accuracy': balanced_accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "        'F1_Score': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "    }\n",
        "\n",
        "    # Additional metrics for binary classification\n",
        "    if task_type == 'binary' and y_pred_proba is not None:\n",
        "        metrics['ROC_AUC'] = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "        metrics['Log_Loss'] = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "    # Top-K accuracy for multiclass (K=2)\n",
        "    if task_type == 'multiclass' and y_pred_proba is not None:\n",
        "        try:\n",
        "            # top_k_accuracy_score requires labels in range [0, n_classes-1]\n",
        "            metrics['Top_2_Accuracy'] = top_k_accuracy_score(y_test, y_pred_proba, k=2)\n",
        "        except:\n",
        "            metrics['Top_2_Accuracy'] = np.nan\n",
        "\n",
        "    # Calculate confusion matrix and error metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    if task_type == 'binary':\n",
        "        # Ensure cm has at least 2x2 dimensions for ravel to work, or handle if only one class predicted/actual\n",
        "        if cm.shape == (1,1):\n",
        "            TN, FP, FN, TP = (cm[0,0], 0, 0, 0) if y_test.iloc[0] == 0 else (0, 0, 0, cm[0,0])\n",
        "        elif cm.shape == (2,2):\n",
        "            TN, FP, FN, TP = cm.ravel()\n",
        "        else: # Handle other unexpected shapes, e.g., only one class in y_test\n",
        "            TN, FP, FN, TP = 0, 0, 0, 0 # Fallback\n",
        "\n",
        "        metrics['False_Positive'] = FP\n",
        "        metrics['False_Negative'] = FN\n",
        "        metrics['Type_I_Error'] = FP  # Same as False Positive\n",
        "        metrics['Type_II_Error'] = FN  # Same as False Negative\n",
        "        metrics['Misclassification_Error'] = (FP + FN) / len(y_test)\n",
        "    else:\n",
        "        # For multiclass, calculate overall misclassification\n",
        "        total_correct = np.trace(cm)\n",
        "        total = np.sum(cm)\n",
        "        metrics['Misclassification_Error'] = (total - total_correct) / total\n",
        "\n",
        "    return metrics, cm, model_to_fit\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic_Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive_Bayes': GaussianNB(),\n",
        "    'Decision_Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random_Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'DNN': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Create ensemble models\n",
        "ensemble_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "ensemble_xgb = XGBClassifier(random_state=42)\n",
        "ensemble_dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', ensemble_rf),\n",
        "        ('xgb', ensemble_xgb),\n",
        "        ('dt', ensemble_dt)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', ensemble_rf),\n",
        "        ('xgb', ensemble_xgb),\n",
        "        ('dt', ensemble_dt)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "models['Voting_Ensemble'] = voting_clf\n",
        "models['Stacking_Ensemble'] = stacking_clf\n",
        "\n",
        "# Results storage\n",
        "all_results = []\n",
        "all_confusion_matrices = {}\n",
        "\n",
        "# Scale features for models that need it\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def scale_features(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    return X_train_scaled, X_test_scaled\n",
        "\n",
        "# Evaluate all models for all feature sets\n",
        "for feature_set_name in feature_sets.keys():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating Feature Set: {feature_set_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Scale features for this feature set\n",
        "    X_train_bin_scaled, X_test_bin_scaled = scale_features(\n",
        "        X_train_bin[feature_set_name], X_test_bin[feature_set_name]\n",
        "    )\n",
        "    X_train_multi_scaled, X_test_multi_scaled = scale_features(\n",
        "        X_train_multi[feature_set_name], X_test_multi[feature_set_name]\n",
        "    )\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "        # Binary classification\n",
        "        metrics_bin, cm_bin, trained_model_bin = evaluate_model(\n",
        "            model, X_train_bin_scaled, X_test_bin_scaled,\n",
        "            y_train_bin[feature_set_name], y_test_bin[feature_set_name],\n",
        "            feature_set_name, 'binary', model_name\n",
        "        )\n",
        "        # Only append results if evaluation was not skipped\n",
        "        if metrics_bin is not None:\n",
        "            all_results.append(metrics_bin)\n",
        "            all_confusion_matrices[f\"{feature_set_name}_{model_name}_binary\"] = cm_bin\n",
        "\n",
        "        # Multiclass classification\n",
        "        metrics_multi, cm_multi, trained_model_multi = evaluate_model(\n",
        "            model, X_train_multi_scaled, X_test_multi_scaled,\n",
        "            y_train_multi[feature_set_name], y_test_multi[feature_set_name],\n",
        "            feature_set_name, 'multiclass', model_name\n",
        "        )\n",
        "        # Only append results if evaluation was not skipped\n",
        "        if metrics_multi is not None:\n",
        "            all_results.append(metrics_multi)\n",
        "            all_confusion_matrices[f\"{feature_set_name}_{model_name}_multiclass\"] = cm_multi\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Display top models for each task\n",
        "for task in ['binary', 'multiclass']:\n",
        "    task_results = results_df[results_df['Task_Type'] == task]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TOP 10 MODELS FOR {task.upper()} CLASSIFICATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Sort by Accuracy\n",
        "    top_accuracy = task_results.sort_values('Accuracy', ascending=False).head(10)\n",
        "    print(\"\\nTop 10 by Accuracy:\")\n",
        "    print(top_accuracy[['Feature_Set', 'Model', 'Accuracy', 'F1_Score', 'Balanced_Accuracy']].to_string())\n",
        "\n",
        "    # Sort by F1-Score\n",
        "    top_f1 = task_results.sort_values('F1_Score', ascending=False).head(10)\n",
        "    print(\"\\nTop 10 by F1-Score:\")\n",
        "    print(top_f1[['Feature_Set', 'Model', 'F1_Score', 'Accuracy', 'Balanced_Accuracy']].to_string())\n",
        "\n",
        "# Compare with vs without ticker\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"COMPARISON: WITH TICKER vs WITHOUT TICKER\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Group by feature sets with and without ticker\n",
        "ticker_results = results_df[results_df['Feature_Set'].str.contains('ticker')]\n",
        "no_ticker_results = results_df[~results_df['Feature_Set'].str.contains('ticker')]\n",
        "\n",
        "for task in ['binary', 'multiclass']:\n",
        "    ticker_task = ticker_results[ticker_results['Task_Type'] == task]\n",
        "    no_ticker_task = no_ticker_results[no_ticker_results['Task_Type'] == task]\n",
        "\n",
        "    print(f\"\\n{task.upper()} CLASSIFICATION:\")\n",
        "    print(f\"{'-'*40}\")\n",
        "    print(f\"With Ticker - Average Accuracy: {ticker_task['Accuracy'].mean():.4f}\")\n",
        "    print(f\"Without Ticker - Average Accuracy: {no_ticker_task['Accuracy'].mean():.4f}\")\n",
        "    print(f\"Difference: {(ticker_task['Accuracy'].mean() - no_ticker_task['Accuracy'].mean()):.4f}\")\n",
        "\n",
        "    print(f\"\\nWith Ticker - Average F1-Score: {ticker_task['F1_Score'].mean():.4f}\")\n",
        "    print(f\"Without Ticker - Average F1-Score: {no_ticker_task['F1_Score'].mean():.4f}\")\n",
        "    print(f\"Difference: {(ticker_task['F1_Score'].mean() - no_ticker_results['F1_Score'].mean()):.4f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Evaluating Feature Set: tabular_only\n",
            "============================================================\n",
            "\n",
            "Training Logistic_Regression...\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "Training Naive_Bayes...\n",
            "\n",
            "Training Decision_Tree...\n",
            "\n",
            "Training Random_Forest...\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Training DNN...\n",
            "\n",
            "Training Voting_Ensemble...\n",
            "\n",
            "Training Stacking_Ensemble...\n",
            "\n",
            "============================================================\n",
            "Evaluating Feature Set: tabular_nlp\n",
            "============================================================\n",
            "\n",
            "Training Logistic_Regression...\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "Training Naive_Bayes...\n",
            "\n",
            "Training Decision_Tree...\n",
            "\n",
            "Training Random_Forest...\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Training DNN...\n",
            "\n",
            "Training Voting_Ensemble...\n",
            "\n",
            "Training Stacking_Ensemble...\n",
            "\n",
            "============================================================\n",
            "Evaluating Feature Set: tabular_ticker\n",
            "============================================================\n",
            "\n",
            "Training Logistic_Regression...\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "Training Naive_Bayes...\n",
            "\n",
            "Training Decision_Tree...\n",
            "\n",
            "Training Random_Forest...\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Training DNN...\n",
            "\n",
            "Training Voting_Ensemble...\n",
            "\n",
            "Training Stacking_Ensemble...\n",
            "\n",
            "============================================================\n",
            "Evaluating Feature Set: tabular_nlp_ticker\n",
            "============================================================\n",
            "\n",
            "Training Logistic_Regression...\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "Training Naive_Bayes...\n",
            "\n",
            "Training Decision_Tree...\n",
            "\n",
            "Training Random_Forest...\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Training DNN...\n",
            "\n",
            "Training Voting_Ensemble...\n",
            "\n",
            "Training Stacking_Ensemble...\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE MODEL EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "TOP 10 MODELS FOR BINARY CLASSIFICATION\n",
            "============================================================\n",
            "\n",
            "Top 10 by Accuracy:\n",
            "           Feature_Set              Model  Accuracy  F1_Score  Balanced_Accuracy\n",
            "78  tabular_nlp_ticker  Stacking_Ensemble  0.834975  0.834641           0.829430\n",
            "58      tabular_ticker  Stacking_Ensemble  0.832512  0.831232           0.822819\n",
            "38         tabular_nlp  Stacking_Ensemble  0.832512  0.832383           0.828028\n",
            "50      tabular_ticker            XGBoost  0.832512  0.831031           0.822074\n",
            "18        tabular_only  Stacking_Ensemble  0.827586  0.826832           0.820015\n",
            "70  tabular_nlp_ticker            XGBoost  0.827586  0.827161           0.821504\n",
            "10        tabular_only            XGBoost  0.822660  0.821700           0.814235\n",
            "30         tabular_nlp            XGBoost  0.822660  0.822524           0.817956\n",
            "76  tabular_nlp_ticker    Voting_Ensemble  0.822660  0.822660           0.818701\n",
            "28         tabular_nlp      Random_Forest  0.820197  0.819671           0.813578\n",
            "\n",
            "Top 10 by F1-Score:\n",
            "           Feature_Set              Model  F1_Score  Accuracy  Balanced_Accuracy\n",
            "78  tabular_nlp_ticker  Stacking_Ensemble  0.834641  0.834975           0.829430\n",
            "38         tabular_nlp  Stacking_Ensemble  0.832383  0.832512           0.828028\n",
            "58      tabular_ticker  Stacking_Ensemble  0.831232  0.832512           0.822819\n",
            "50      tabular_ticker            XGBoost  0.831031  0.832512           0.822074\n",
            "70  tabular_nlp_ticker            XGBoost  0.827161  0.827586           0.821504\n",
            "18        tabular_only  Stacking_Ensemble  0.826832  0.827586           0.820015\n",
            "76  tabular_nlp_ticker    Voting_Ensemble  0.822660  0.822660           0.818701\n",
            "30         tabular_nlp            XGBoost  0.822524  0.822660           0.817956\n",
            "10        tabular_only            XGBoost  0.821700  0.822660           0.814235\n",
            "28         tabular_nlp      Random_Forest  0.819671  0.820197           0.813578\n",
            "\n",
            "============================================================\n",
            "TOP 10 MODELS FOR MULTICLASS CLASSIFICATION\n",
            "============================================================\n",
            "\n",
            "Top 10 by Accuracy:\n",
            "           Feature_Set              Model  Accuracy  F1_Score  Balanced_Accuracy\n",
            "9         tabular_only      Random_Forest  0.561576  0.544556           0.440070\n",
            "19        tabular_only  Stacking_Ensemble  0.551724  0.533771           0.313161\n",
            "59      tabular_ticker  Stacking_Ensemble  0.549261  0.535634           0.325649\n",
            "11        tabular_only            XGBoost  0.549261  0.536589           0.437337\n",
            "39         tabular_nlp  Stacking_Ensemble  0.546798  0.531522           0.325454\n",
            "49      tabular_ticker      Random_Forest  0.544335  0.524589           0.423339\n",
            "79  tabular_nlp_ticker  Stacking_Ensemble  0.541872  0.525507           0.313798\n",
            "31         tabular_nlp            XGBoost  0.541872  0.528355           0.441301\n",
            "51      tabular_ticker            XGBoost  0.536946  0.525639           0.442175\n",
            "71  tabular_nlp_ticker            XGBoost  0.532020  0.520501           0.435080\n",
            "\n",
            "Top 10 by F1-Score:\n",
            "           Feature_Set              Model  F1_Score  Accuracy  Balanced_Accuracy\n",
            "9         tabular_only      Random_Forest  0.544556  0.561576           0.440070\n",
            "11        tabular_only            XGBoost  0.536589  0.549261           0.437337\n",
            "59      tabular_ticker  Stacking_Ensemble  0.535634  0.549261           0.325649\n",
            "19        tabular_only  Stacking_Ensemble  0.533771  0.551724           0.313161\n",
            "39         tabular_nlp  Stacking_Ensemble  0.531522  0.546798           0.325454\n",
            "31         tabular_nlp            XGBoost  0.528355  0.541872           0.441301\n",
            "51      tabular_ticker            XGBoost  0.525639  0.536946           0.442175\n",
            "79  tabular_nlp_ticker  Stacking_Ensemble  0.525507  0.541872           0.313798\n",
            "49      tabular_ticker      Random_Forest  0.524589  0.544335           0.423339\n",
            "71  tabular_nlp_ticker            XGBoost  0.520501  0.532020           0.435080\n",
            "\n",
            "================================================================================\n",
            "COMPARISON: WITH TICKER vs WITHOUT TICKER\n",
            "================================================================================\n",
            "\n",
            "BINARY CLASSIFICATION:\n",
            "----------------------------------------\n",
            "With Ticker - Average Accuracy: 0.7331\n",
            "Without Ticker - Average Accuracy: 0.7281\n",
            "Difference: 0.0050\n",
            "\n",
            "With Ticker - Average F1-Score: 0.7161\n",
            "Without Ticker - Average F1-Score: 0.7106\n",
            "Difference: 0.1757\n",
            "\n",
            "MULTICLASS CLASSIFICATION:\n",
            "----------------------------------------\n",
            "With Ticker - Average Accuracy: 0.4042\n",
            "Without Ticker - Average Accuracy: 0.4009\n",
            "Difference: 0.0033\n",
            "\n",
            "With Ticker - Average F1-Score: 0.3734\n",
            "Without Ticker - Average F1-Score: 0.3703\n",
            "Difference: -0.1670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uX8ZA-q-v4dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAklT-OSv4aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7YfK_0Bv4YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6rVTCtTv4Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6QK1PUiv4TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXjh5ct8v4Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTUZH2n3v4ON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}