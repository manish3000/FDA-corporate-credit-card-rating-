{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn4IPwU1BQL",
        "outputId": "5ccc8b03-379a-45db-a0c6-2386d5ca0e8e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data (assuming df is already loaded)\n",
        "df = pd.read_csv('01_credit_ratings_tabular_clean.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "print(\"Starting data preprocessing...\")\n",
        "\n",
        "# Drop specified columns\n",
        "df = df.drop(['Rating', 'Name', 'Rating Agency Name'], axis=1)\n",
        "\n",
        "# Convert Date to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract useful features from date\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Quarter'] = df['Date'].dt.quarter\n",
        "df = df.drop(['Date'], axis=1)\n",
        "\n",
        "# Encode Sector and Ticker\n",
        "le_sector = LabelEncoder()\n",
        "le_ticker = LabelEncoder()\n",
        "df['Sector_Encoded'] = le_sector.fit_transform(df['Sector'])\n",
        "df['Ticker_Encoded'] = le_ticker.fit_transform(df['Ticker'])\n",
        "df = df.drop(['Sector', 'Ticker'], axis=1)\n",
        "\n",
        "# Ensure all feature columns are numeric before splitting X and y\n",
        "# Identify columns that are not the target variables and are not numeric\n",
        "\n",
        "target_cols = ['Rating_Encoded_Multiclass', 'Rating_Encoded_Binary']\n",
        "\n",
        "# Temporarily drop target columns to check feature dtypes, ignoring errors if they don't exist yet\n",
        "feature_df_check = df.drop(columns=target_cols, errors='ignore')\n",
        "\n",
        "non_numeric_feature_cols = feature_df_check.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "if len(non_numeric_feature_cols) > 0:\n",
        "    print(f\"Non-numeric feature columns found: {non_numeric_feature_cols.tolist()}\")\n",
        "    for col in non_numeric_feature_cols:\n",
        "        # Attempt to convert to numeric, coercing errors\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        # If conversion results in NaNs, it means the column could not be fully converted.\n",
        "        # In such cases, we drop the column to ensure all features are numeric.\n",
        "        if df[col].isnull().any():\n",
        "            print(f\"Column '{col}' could not be fully converted to numeric and contains NaNs. Dropping it.\")\n",
        "            df = df.drop(columns=[col])\n",
        "    print(\"Attempted to convert/drop non-numeric columns in features.\")\n",
        "else:\n",
        "    print(\"No non-numeric feature columns found in df after initial preprocessing.\")\n",
        "\n",
        "\n",
        "# Separate features and targets\n",
        "X = df.drop(target_cols, axis=1)\n",
        "y_binary = df['Rating_Encoded_Binary']\n",
        "y_multiclass = df['Rating_Encoded_Multiclass']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train_bin, y_test_bin = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
        "    X, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_multi_scaled = scaler.fit_transform(X_train_multi)\n",
        "X_test_multi_scaled = scaler.transform(X_test_multi)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Binary class distribution: {np.bincount(y_binary)}\")\n",
        "print(f\"Multiclass distribution: {np.bincount(y_multiclass)}\")\n",
        "print(\"Preprocessing completed!\\n\")\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, multiclass=False, model_name=\"\"):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "\n",
        "    # Train and predict\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    if multiclass:\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "        # For multiclass, use average='macro' or 'weighted'\n",
        "        avg_method = 'macro'\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "\n",
        "        # ROC-AUC (one-vs-rest for multiclass)\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average=avg_method)\n",
        "            else:\n",
        "                roc_auc = 0.0\n",
        "        except:\n",
        "            roc_auc = 0.0\n",
        "\n",
        "        # Log Loss\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                loss = log_loss(y_test, y_pred_proba)\n",
        "            else:\n",
        "                loss = 0.0\n",
        "        except:\n",
        "            loss = 0.0\n",
        "\n",
        "        # Top-K accuracy (K=2)\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                top_k_acc = top_k_accuracy_score(y_test, y_pred_proba, k=2)\n",
        "            else:\n",
        "                top_k_acc = 0.0\n",
        "        except:\n",
        "            top_k_acc = 0.0\n",
        "\n",
        "    else:\n",
        "        # Binary classification\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        try:\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            has_proba = True\n",
        "        except:\n",
        "            y_pred_proba = None\n",
        "            has_proba = False\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        # ROC-AUC\n",
        "        if has_proba:\n",
        "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "            loss = log_loss(y_test, y_pred_proba)\n",
        "        else:\n",
        "            roc_auc = 0.0\n",
        "            loss = 0.0\n",
        "\n",
        "        top_k_acc = accuracy  # Top-K not typically used for binary\n",
        "\n",
        "        # Calculate confusion matrix for error analysis\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "        error_metrics = {\n",
        "            'False Positive': fp,\n",
        "            'False Negative': fn,\n",
        "            'Type I Error': fp,  # Same as False Positive\n",
        "            'Type II Error': fn,  # Same as False Negative\n",
        "            'Total Errors': fp + fn,\n",
        "            'Error Rate': (fp + fn) / len(y_test)\n",
        "        }\n",
        "\n",
        "    # Calculate bias and variance proxies\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_acc = accuracy_score(y_train, train_pred)\n",
        "    bias_error = 1 - train_acc\n",
        "    variance_error = abs(train_acc - accuracy)\n",
        "\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Top-K Accuracy': top_k_acc,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Log Loss': loss,\n",
        "        'Bias Error': bias_error,\n",
        "        'Variance Error': variance_error,\n",
        "        'Misclassification Error': 1 - accuracy\n",
        "    }\n",
        "\n",
        "    if not multiclass:\n",
        "        metrics.update(error_metrics)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Import models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# For top-k accuracy\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "print(\"Training and evaluating models...\\n\")\n",
        "\n",
        "# Initialize results storage\n",
        "binary_results = []\n",
        "multiclass_results = []\n",
        "\n",
        "# 1. LINEAR MODEL (Logistic Regression)\n",
        "print(\"1. Training Logistic Regression...\")\n",
        "log_reg_bin = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "log_reg_multi = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced', multi_class='multinomial')\n",
        "\n",
        "binary_results.append(evaluate_model(log_reg_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Logistic Regression\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(log_reg_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Logistic Regression\"))\n",
        "\n",
        "# 2. K-NEAREST NEIGHBORS\n",
        "print(\"2. Training KNN...\")\n",
        "knn_bin = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_multi = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "binary_results.append(evaluate_model(knn_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"KNN\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(knn_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"KNN\"))\n",
        "\n",
        "# 3. NAIVE BAYES\n",
        "print(\"3. Training Naive Bayes...\")\n",
        "nb_bin = GaussianNB()\n",
        "nb_multi = GaussianNB()\n",
        "\n",
        "binary_results.append(evaluate_model(nb_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Naive Bayes\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(nb_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Naive Bayes\"))\n",
        "\n",
        "# 4. DECISION TREE\n",
        "print(\"4. Training Decision Tree...\")\n",
        "dt_bin = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)\n",
        "dt_multi = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)\n",
        "\n",
        "binary_results.append(evaluate_model(dt_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Decision Tree\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(dt_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Decision Tree\"))\n",
        "\n",
        "# 5. RANDOM FOREST\n",
        "print(\"5. Training Random Forest...\")\n",
        "rf_bin = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15,\n",
        "                               min_samples_split=5, class_weight='balanced')\n",
        "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15,\n",
        "                                 min_samples_split=5, class_weight='balanced')\n",
        "\n",
        "binary_results.append(evaluate_model(rf_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Random Forest\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(rf_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Random Forest\"))\n",
        "\n",
        "# 6. XGBOOST\n",
        "print(\"6. Training XGBoost...\")\n",
        "xgb_bin = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6,\n",
        "                           random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
        "xgb_multi = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6,\n",
        "                             random_state=42, eval_metric='mlogloss', use_label_encoder=False)\n",
        "\n",
        "binary_results.append(evaluate_model(xgb_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"XGBoost\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(xgb_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"XGBoost\"))\n",
        "\n",
        "# 7. SUPPORT VECTOR MACHINE\n",
        "print(\"7. Training SVM...\")\n",
        "svm_bin = SVC(probability=True, random_state=42, class_weight='balanced')\n",
        "svm_multi = SVC(probability=True, random_state=42, class_weight='balanced', decision_function_shape='ovr')\n",
        "\n",
        "binary_results.append(evaluate_model(svm_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"SVM\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(svm_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"SVM\"))\n",
        "\n",
        "# 8. SIMPLE DNN (Multi-layer Perceptron)\n",
        "print(\"8. Training DNN...\")\n",
        "dnn_bin = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu',\n",
        "                       max_iter=500, random_state=42, early_stopping=True)\n",
        "dnn_multi = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu',\n",
        "                         max_iter=500, random_state=42, early_stopping=True)\n",
        "\n",
        "binary_results.append(evaluate_model(dnn_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"DNN\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(dnn_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"DNN\"))\n",
        "\n",
        "# 9. ENSEMBLE TECHNIQUES\n",
        "print(\"9. Training Ensemble Models...\")\n",
        "\n",
        "# Bagging Ensemble\n",
        "bagging_bin = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=10),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_multi = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=10),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(bagging_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Bagging Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(bagging_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Bagging Ensemble\"))\n",
        "\n",
        "# Voting Ensemble\n",
        "voting_bin = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "        ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False)),\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_multi = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "        ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False)),\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial'))\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(voting_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Voting Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(voting_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Voting Ensemble\"))\n",
        "\n",
        "# Stacking Ensemble\n",
        "base_estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "    ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "stacking_bin = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "stacking_multi = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=LogisticRegression(multi_class='multinomial'),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(stacking_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Stacking Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(stacking_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Stacking Ensemble\"))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert results to DataFrames\n",
        "binary_df = pd.DataFrame(binary_results)\n",
        "multiclass_df = pd.DataFrame(multiclass_results)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nBINARY CLASSIFICATION RESULTS (Investment Grade vs Below Investment Grade):\")\n",
        "print(\"-\"*80)\n",
        "display_cols = ['Model', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall',\n",
        "                'F1-Score', 'ROC-AUC', 'Log Loss', 'Misclassification Error']\n",
        "print(binary_df[display_cols].round(4).to_string())\n",
        "\n",
        "print(\"\\n\\nMULTICLASS CLASSIFICATION RESULTS (6 rating categories):\")\n",
        "print(\"-\"*80)\n",
        "print(multiclass_df[display_cols].round(4).to_string())\n",
        "\n",
        "# Display error analysis for binary classification\n",
        "print(\"\\n\\nERROR ANALYSIS FOR BINARY CLASSIFICATION:\")\n",
        "print(\"-\"*80)\n",
        "error_cols = ['Model', 'False Positive', 'False Negative', 'Type I Error',\n",
        "              'Type II Error', 'Total Errors', 'Error Rate', 'Bias Error', 'Variance Error']\n",
        "print(binary_df[error_cols].round(4).to_string())\n",
        "\n",
        "# Rank models by accuracy\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"MODEL RANKING BY ACCURACY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nBINARY CLASSIFICATION - Top Models:\")\n",
        "binary_ranked = binary_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "binary_ranked['Rank'] = binary_ranked.index + 1\n",
        "print(binary_ranked[['Rank', 'Model', 'Accuracy', 'F1-Score', 'ROC-AUC']].round(4).to_string())\n",
        "\n",
        "print(\"\\nMULTICLASS CLASSIFICATION - Top Models:\")\n",
        "multiclass_ranked = multiclass_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "multiclass_ranked['Rank'] = multiclass_ranked.index + 1\n",
        "print(multiclass_ranked[['Rank', 'Model', 'Accuracy', 'F1-Score', 'ROC-AUC']].round(4).to_string())\n",
        "\n",
        "# Best overall models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST OVERALL MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nBEST FOR BINARY CLASSIFICATION:\")\n",
        "best_binary = binary_ranked.iloc[0]\n",
        "print(f\"Model: {best_binary['Model']}\")\n",
        "print(f\"Accuracy: {best_binary['Accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {best_binary['F1-Score']:.4f}\")\n",
        "print(f\"ROC-AUC: {best_binary['ROC-AUC']:.4f}\")\n",
        "\n",
        "print(f\"\\nBEST FOR MULTICLASS CLASSIFICATION:\")\n",
        "best_multi = multiclass_ranked.iloc[0]\n",
        "print(f\"Model: {best_multi['Model']}\")\n",
        "print(f\"Accuracy: {best_multi['Accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {best_multi['F1-Score']:.4f}\")\n",
        "print(f\"ROC-AUC: {best_multi['ROC-AUC']:.4f}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE SUMMARY STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nBinary Classification - Average Performance:\")\n",
        "binary_avg = binary_df[['Accuracy', 'Balanced Accuracy', 'F1-Score', 'ROC-AUC']].mean()\n",
        "print(binary_avg.round(4).to_string())\n",
        "\n",
        "print(\"\\nMulticlass Classification - Average Performance:\")\n",
        "multi_avg = multiclass_df[['Accuracy', 'Balanced Accuracy', 'F1-Score', 'ROC-AUC']].mean()\n",
        "print(multi_avg.round(4).to_string())\n",
        "\n",
        "# Feature importance for tree-based models\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS (from Random Forest)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf_model = rf_bin\n",
        "rf_model.fit(X_train_scaled, y_train_bin)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).round(4).to_string())\n",
        "\n",
        "print(\"\\nBottom 10 Least Important Features:\")\n",
        "print(feature_importance.tail(10).round(4).to_string())\n",
        "\n",
        "# Additional insights\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS AND RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. Best Performing Model Types:\")\n",
        "print(\"   - For binary classification: Ensemble methods (Stacking, Voting, Random Forest)\")\n",
        "print(\"   - For multiclass classification: XGBoost and Random Forest\")\n",
        "\n",
        "print(\"\\n2. Error Analysis:\")\n",
        "print(\"   - Type I Errors (False Positives): Classifying risky companies as investment grade\")\n",
        "print(\"   - Type II Errors (False Negatives): Missing investment opportunities\")\n",
        "print(\"   - Consider cost-sensitive learning for financial applications\")\n",
        "\n",
        "print(\"\\n3. Recommendations:\")\n",
        "print(\"   - Use ensemble methods for robust performance\")\n",
        "print(\"   - Consider feature engineering based on important features\")\n",
        "print(\"   - Implement cross-validation for model stability\")\n",
        "print(\"   - Use probability thresholds for risk management\")\n",
        "print(\"   - Consider time-series aspects if data spans multiple periods\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preprocessing...\n",
            "Non-numeric feature columns found: ['Rating_Merged']\n",
            "Column 'Rating_Merged' could not be fully converted to numeric and contains NaNs. Dropping it.\n",
            "Attempted to convert/drop non-numeric columns in features.\n",
            "Training samples: 1623, Test samples: 406\n",
            "Binary class distribution: [ 864 1165]\n",
            "Multiclass distribution: [398  89   7 302 490 671  64   8]\n",
            "Preprocessing completed!\n",
            "\n",
            "Training and evaluating models...\n",
            "\n",
            "1. Training Logistic Regression...\n",
            "2. Training KNN...\n",
            "3. Training Naive Bayes...\n",
            "4. Training Decision Tree...\n",
            "5. Training Random Forest...\n",
            "6. Training XGBoost...\n",
            "7. Training SVM...\n",
            "8. Training DNN...\n",
            "9. Training Ensemble Models...\n",
            "\n",
            "================================================================================\n",
            "MODEL EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "BINARY CLASSIFICATION RESULTS (Investment Grade vs Below Investment Grade):\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  Accuracy  Balanced Accuracy  Precision  Recall  F1-Score  ROC-AUC  Log Loss  Misclassification Error\n",
            "0   Logistic Regression    0.6626             0.6561     0.7087  0.6996    0.7041   0.7093    0.7986                   0.3374\n",
            "1                   KNN    0.5887             0.5694     0.6269  0.6996    0.6613   0.6330    1.7549                   0.4113\n",
            "2           Naive Bayes    0.6305             0.5680     0.6095  0.9914    0.7549   0.6246   12.5841                   0.3695\n",
            "3         Decision Tree    0.7315             0.7185     0.7460  0.8069    0.7753   0.7024    6.1351                   0.2685\n",
            "4         Random Forest    0.8227             0.8142     0.8286  0.8712    0.8494   0.8906    0.4261                   0.1773\n",
            "5               XGBoost    0.8374             0.8286     0.8381  0.8884    0.8625   0.8941    0.4115                   0.1626\n",
            "6                   SVM    0.6823             0.6577     0.6857  0.8240    0.7485   0.7076    0.6153                   0.3177\n",
            "7                   DNN    0.6995             0.6697     0.6881  0.8712    0.7689   0.7256    0.7072                   0.3005\n",
            "8      Bagging Ensemble    0.8030             0.7904     0.8000  0.8755    0.8361   0.8825    0.4274                   0.1970\n",
            "9       Voting Ensemble    0.8276             0.8148     0.8171  0.9013    0.8571   0.8951    0.4274                   0.1724\n",
            "10    Stacking Ensemble    0.8325             0.8236     0.8340  0.8841    0.8583   0.8995    0.3965                   0.1675\n",
            "\n",
            "\n",
            "MULTICLASS CLASSIFICATION RESULTS (6 rating categories):\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  Accuracy  Balanced Accuracy  Precision  Recall  F1-Score  ROC-AUC  Log Loss  Misclassification Error\n",
            "0   Logistic Regression    0.2143             0.3600     0.2046  0.3600    0.1678   0.7018    1.9899                   0.7857\n",
            "1                   KNN    0.3645             0.2089     0.2071  0.2089    0.2040   0.6814    8.3917                   0.6355\n",
            "2           Naive Bayes    0.0813             0.2572     0.1780  0.2572    0.0685   0.5524   28.4451                   0.9187\n",
            "3         Decision Tree    0.3916             0.2306     0.2432  0.2306    0.2311   0.6533   12.7097                   0.6084\n",
            "4         Random Forest    0.5148             0.4333     0.4713  0.4333    0.4439   0.8574    1.2984                   0.4852\n",
            "5               XGBoost    0.5517             0.4394     0.5148  0.4394    0.4495   0.8648    1.1733                   0.4483\n",
            "6                   SVM    0.2635             0.3867     0.2199  0.3867    0.2041   0.7338    1.5119                   0.7365\n",
            "7                   DNN    0.3300             0.1448     0.1506  0.1448    0.1259   0.7093    1.5841                   0.6700\n",
            "8      Bagging Ensemble    0.5148             0.4290     0.5469  0.4290    0.4511   0.8065    1.3093                   0.4852\n",
            "9       Voting Ensemble    0.5764             0.4409     0.5067  0.4409    0.4464   0.8745    1.1780                   0.4236\n",
            "10    Stacking Ensemble    0.5616             0.3277     0.3701  0.3277    0.3346   0.8854    1.1317                   0.4384\n",
            "\n",
            "\n",
            "ERROR ANALYSIS FOR BINARY CLASSIFICATION:\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  False Positive  False Negative  Type I Error  Type II Error  Total Errors  Error Rate  Bias Error  Variance Error\n",
            "0   Logistic Regression              67              70            67             70           137      0.3374      0.3487          0.0113\n",
            "1                   KNN              97              70            97             70           167      0.4113      0.2360          0.1753\n",
            "2           Naive Bayes             148               2           148              2           150      0.3695      0.3980          0.0286\n",
            "3         Decision Tree              64              45            64             45           109      0.2685      0.0696          0.1988\n",
            "4         Random Forest              42              30            42             30            72      0.1773      0.0025          0.1749\n",
            "5               XGBoost              40              26            40             26            66      0.1626      0.0000          0.1626\n",
            "6                   SVM              88              41            88             41           129      0.3177      0.3376          0.0199\n",
            "7                   DNN              92              30            92             30           122      0.3005      0.2754          0.0251\n",
            "8      Bagging Ensemble              51              29            51             29            80      0.1970      0.0474          0.1496\n",
            "9       Voting Ensemble              47              23            47             23            70      0.1724      0.0000          0.1724\n",
            "10    Stacking Ensemble              41              27            41             27            68      0.1675      0.0000          0.1675\n",
            "\n",
            "\n",
            "================================================================================\n",
            "MODEL RANKING BY ACCURACY\n",
            "================================================================================\n",
            "\n",
            "BINARY CLASSIFICATION - Top Models:\n",
            "    Rank                Model  Accuracy  F1-Score  ROC-AUC\n",
            "0      1              XGBoost    0.8374    0.8625   0.8941\n",
            "1      2    Stacking Ensemble    0.8325    0.8583   0.8995\n",
            "2      3      Voting Ensemble    0.8276    0.8571   0.8951\n",
            "3      4        Random Forest    0.8227    0.8494   0.8906\n",
            "4      5     Bagging Ensemble    0.8030    0.8361   0.8825\n",
            "5      6        Decision Tree    0.7315    0.7753   0.7024\n",
            "6      7                  DNN    0.6995    0.7689   0.7256\n",
            "7      8                  SVM    0.6823    0.7485   0.7076\n",
            "8      9  Logistic Regression    0.6626    0.7041   0.7093\n",
            "9     10          Naive Bayes    0.6305    0.7549   0.6246\n",
            "10    11                  KNN    0.5887    0.6613   0.6330\n",
            "\n",
            "MULTICLASS CLASSIFICATION - Top Models:\n",
            "    Rank                Model  Accuracy  F1-Score  ROC-AUC\n",
            "0      1      Voting Ensemble    0.5764    0.4464   0.8745\n",
            "1      2    Stacking Ensemble    0.5616    0.3346   0.8854\n",
            "2      3              XGBoost    0.5517    0.4495   0.8648\n",
            "3      4     Bagging Ensemble    0.5148    0.4511   0.8065\n",
            "4      5        Random Forest    0.5148    0.4439   0.8574\n",
            "5      6        Decision Tree    0.3916    0.2311   0.6533\n",
            "6      7                  KNN    0.3645    0.2040   0.6814\n",
            "7      8                  DNN    0.3300    0.1259   0.7093\n",
            "8      9                  SVM    0.2635    0.2041   0.7338\n",
            "9     10  Logistic Regression    0.2143    0.1678   0.7018\n",
            "10    11          Naive Bayes    0.0813    0.0685   0.5524\n",
            "\n",
            "================================================================================\n",
            "BEST OVERALL MODELS\n",
            "================================================================================\n",
            "\n",
            "BEST FOR BINARY CLASSIFICATION:\n",
            "Model: XGBoost\n",
            "Accuracy: 0.8374\n",
            "F1-Score: 0.8625\n",
            "ROC-AUC: 0.8941\n",
            "\n",
            "BEST FOR MULTICLASS CLASSIFICATION:\n",
            "Model: Voting Ensemble\n",
            "Accuracy: 0.5764\n",
            "F1-Score: 0.4464\n",
            "ROC-AUC: 0.8745\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE SUMMARY STATISTICS\n",
            "================================================================================\n",
            "\n",
            "Binary Classification - Average Performance:\n",
            "Accuracy             0.7380\n",
            "Balanced Accuracy    0.7192\n",
            "F1-Score             0.7888\n",
            "ROC-AUC              0.7786\n",
            "\n",
            "Multiclass Classification - Average Performance:\n",
            "Accuracy             0.3968\n",
            "Balanced Accuracy    0.3326\n",
            "F1-Score             0.2842\n",
            "ROC-AUC              0.7564\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FEATURE IMPORTANCE ANALYSIS (from Random Forest)\n",
            "================================================================================\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                               Feature  Importance\n",
            "22           operatingCashFlowPerShare      0.0852\n",
            "8                       returnOnAssets      0.0600\n",
            "23         operatingCashFlowSalesRatio      0.0570\n",
            "9              returnOnCapitalEmployed      0.0525\n",
            "10                      returnOnEquity      0.0473\n",
            "4                      netProfitMargin      0.0462\n",
            "20                      ebitPerRevenue      0.0428\n",
            "5                   pretaxProfitMargin      0.0387\n",
            "15                    effectiveTaxRate      0.0367\n",
            "16  freeCashFlowOperatingCashFlowRatio      0.0362\n",
            "\n",
            "Bottom 10 Least Important Features:\n",
            "                    Feature  Importance\n",
            "18             cashPerShare      0.0262\n",
            "19  companyEquityMultiplier      0.0258\n",
            "24         payablesTurnover      0.0247\n",
            "29           Ticker_Encoded      0.0244\n",
            "13          debtEquityRatio      0.0233\n",
            "6         grossProfitMargin      0.0232\n",
            "28           Sector_Encoded      0.0165\n",
            "25                     Year      0.0121\n",
            "26                    Month      0.0097\n",
            "27                  Quarter      0.0052\n",
            "\n",
            "================================================================================\n",
            "KEY INSIGHTS AND RECOMMENDATIONS\n",
            "================================================================================\n",
            "\n",
            "1. Best Performing Model Types:\n",
            "   - For binary classification: Ensemble methods (Stacking, Voting, Random Forest)\n",
            "   - For multiclass classification: XGBoost and Random Forest\n",
            "\n",
            "2. Error Analysis:\n",
            "   - Type I Errors (False Positives): Classifying risky companies as investment grade\n",
            "   - Type II Errors (False Negatives): Missing investment opportunities\n",
            "   - Consider cost-sensitive learning for financial applications\n",
            "\n",
            "3. Recommendations:\n",
            "   - Use ensemble methods for robust performance\n",
            "   - Consider feature engineering based on important features\n",
            "   - Implement cross-validation for model stability\n",
            "   - Use probability thresholds for risk management\n",
            "   - Consider time-series aspects if data spans multiple periods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ehh6qvujm4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZ30ikzGjm1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lGXPZtvLjmyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wh_S86S5jmwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWIr1zQfjmt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data (assuming df is already loaded)\n",
        "df = pd.read_csv('01_credit_ratings_tabular_clean.csv')\n",
        "\n",
        "# CORRECTED DATA PREPROCESSING WITHOUT TICKER\n",
        "print(\"Starting CORRECTED data preprocessing (without ticker)...\")\n",
        "\n",
        "# Drop specified columns - REMOVING TICKER\n",
        "df = df.drop(['Rating', 'Name', 'Rating Agency Name', 'Ticker'], axis=1)  # Ticker removed here\n",
        "\n",
        "# Convert Date to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract useful features from date\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Quarter'] = df['Date'].dt.quarter\n",
        "df = df.drop(['Date'], axis=1)\n",
        "\n",
        "# Encode ONLY Sector (not Ticker)\n",
        "le_sector = LabelEncoder()\n",
        "df['Sector_Encoded'] = le_sector.fit_transform(df['Sector'])\n",
        "df = df.drop(['Sector'], axis=1)\n",
        "\n",
        "# Define target columns\n",
        "target_cols = ['Rating_Encoded_Multiclass', 'Rating_Encoded_Binary']\n",
        "\n",
        "# Ensure all feature columns are numeric before splitting X and y\n",
        "# Identify columns that are not the target variables and are not numeric\n",
        "feature_df_check = df.drop(columns=target_cols, errors='ignore')\n",
        "non_numeric_feature_cols = feature_df_check.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "if len(non_numeric_feature_cols) > 0:\n",
        "    print(f\"Non-numeric feature columns found: {non_numeric_feature_cols.tolist()}\")\n",
        "    for col in non_numeric_feature_cols:\n",
        "        # Attempt to convert to numeric, coercing errors\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        # If conversion results in NaNs, it means the column could not be fully converted.\n",
        "        # In such cases, we drop the column to ensure all features are numeric.\n",
        "        if df[col].isnull().any():\n",
        "            print(f\"Column '{col}' could not be fully converted to numeric and contains NaNs. Dropping it.\")\n",
        "            df = df.drop(columns=[col])\n",
        "    print(\"Attempted to convert/drop non-numeric columns in features.\")\n",
        "else:\n",
        "    print(\"No non-numeric feature columns found in df after initial preprocessing.\")\n",
        "\n",
        "# Separate features and targets\n",
        "X = df.drop(target_cols, axis=1)\n",
        "y_binary = df['Rating_Encoded_Binary']\n",
        "y_multiclass = df['Rating_Encoded_Multiclass']\n",
        "\n",
        "print(f\"Features after preprocessing: {X.columns.tolist()}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train_bin, y_test_bin = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
        "    X, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_multi_scaled = scaler.fit_transform(X_train_multi)\n",
        "X_test_multi_scaled = scaler.transform(X_test_multi)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Binary class distribution - Training: {np.bincount(y_train_bin)}, Test: {np.bincount(y_test_bin)}\")\n",
        "print(f\"Multiclass distribution - Training: {np.bincount(y_train_multi)}, Test: {np.bincount(y_test_multi)}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(\"Preprocessing completed without ticker!\\n\")\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, multiclass=False, model_name=\"\"):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "\n",
        "    # Train and predict\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    if multiclass:\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "        # For multiclass, use average='macro' or 'weighted'\n",
        "        avg_method = 'macro'\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average=avg_method, zero_division=0)\n",
        "\n",
        "        # ROC-AUC (one-vs-rest for multiclass)\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average=avg_method)\n",
        "            else:\n",
        "                roc_auc = 0.0\n",
        "        except:\n",
        "            roc_auc = 0.0\n",
        "\n",
        "        # Log Loss\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                loss = log_loss(y_test, y_pred_proba)\n",
        "            else:\n",
        "                loss = 0.0\n",
        "        except:\n",
        "            loss = 0.0\n",
        "\n",
        "        # Top-K accuracy (K=2)\n",
        "        try:\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                from sklearn.metrics import top_k_accuracy_score\n",
        "                top_k_acc = top_k_accuracy_score(y_test, y_pred_proba, k=2)\n",
        "            else:\n",
        "                top_k_acc = 0.0\n",
        "        except:\n",
        "            top_k_acc = 0.0\n",
        "\n",
        "    else:\n",
        "        # Binary classification\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        try:\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            has_proba = True\n",
        "        except:\n",
        "            y_pred_proba = None\n",
        "            has_proba = False\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        # ROC-AUC\n",
        "        if has_proba:\n",
        "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "            loss = log_loss(y_test, y_pred_proba)\n",
        "        else:\n",
        "            roc_auc = 0.0\n",
        "            loss = 0.0\n",
        "\n",
        "        top_k_acc = accuracy  # Top-K not typically used for binary\n",
        "\n",
        "        # Calculate confusion matrix for error analysis\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "        else:\n",
        "            # Handle edge case\n",
        "            fp, fn = 0, 0\n",
        "            if len(cm) > 0:\n",
        "                fp = cm[0, 1] if cm.shape[1] > 1 else 0\n",
        "                fn = cm[1, 0] if cm.shape[0] > 1 else 0\n",
        "\n",
        "        error_metrics = {\n",
        "            'False Positive': fp,\n",
        "            'False Negative': fn,\n",
        "            'Type I Error': fp,  # Same as False Positive\n",
        "            'Type II Error': fn,  # Same as False Negative\n",
        "            'Total Errors': fp + fn,\n",
        "            'Error Rate': (fp + fn) / len(y_test) if len(y_test) > 0 else 0\n",
        "        }\n",
        "\n",
        "    # Calculate bias and variance proxies\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_acc = accuracy_score(y_train, train_pred)\n",
        "    bias_error = 1 - train_acc\n",
        "    variance_error = abs(train_acc - accuracy)\n",
        "\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Top-K Accuracy': top_k_acc,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Log Loss': loss,\n",
        "        'Bias Error': bias_error,\n",
        "        'Variance Error': variance_error,\n",
        "        'Misclassification Error': 1 - accuracy\n",
        "    }\n",
        "\n",
        "    if not multiclass:\n",
        "        metrics.update(error_metrics)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Import models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "print(\"Training and evaluating models WITHOUT TICKER...\\n\")\n",
        "\n",
        "# Initialize results storage\n",
        "binary_results = []\n",
        "multiclass_results = []\n",
        "\n",
        "# 1. LINEAR MODEL (Logistic Regression)\n",
        "print(\"1. Training Logistic Regression...\")\n",
        "log_reg_bin = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "log_reg_multi = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced', multi_class='multinomial')\n",
        "\n",
        "binary_results.append(evaluate_model(log_reg_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Logistic Regression\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(log_reg_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Logistic Regression\"))\n",
        "\n",
        "# 2. K-NEAREST NEIGHBORS\n",
        "print(\"2. Training KNN...\")\n",
        "knn_bin = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_multi = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "binary_results.append(evaluate_model(knn_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"KNN\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(knn_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"KNN\"))\n",
        "\n",
        "# 3. NAIVE BAYES\n",
        "print(\"3. Training Naive Bayes...\")\n",
        "nb_bin = GaussianNB()\n",
        "nb_multi = GaussianNB()\n",
        "\n",
        "binary_results.append(evaluate_model(nb_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Naive Bayes\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(nb_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Naive Bayes\"))\n",
        "\n",
        "# 4. DECISION TREE\n",
        "print(\"4. Training Decision Tree...\")\n",
        "dt_bin = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5, class_weight='balanced')\n",
        "dt_multi = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5, class_weight='balanced')\n",
        "\n",
        "binary_results.append(evaluate_model(dt_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Decision Tree\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(dt_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Decision Tree\"))\n",
        "\n",
        "# 5. RANDOM FOREST\n",
        "print(\"5. Training Random Forest...\")\n",
        "rf_bin = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15,\n",
        "                               min_samples_split=5, class_weight='balanced', n_jobs=-1)\n",
        "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15,\n",
        "                                 min_samples_split=5, class_weight='balanced', n_jobs=-1)\n",
        "\n",
        "binary_results.append(evaluate_model(rf_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Random Forest\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(rf_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Random Forest\"))\n",
        "\n",
        "# 6. XGBOOST\n",
        "print(\"6. Training XGBoost...\")\n",
        "xgb_bin = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6,\n",
        "                           random_state=42, eval_metric='logloss', use_label_encoder=False,\n",
        "                           scale_pos_weight=len(y_train_bin[y_train_bin==0])/len(y_train_bin[y_train_bin==1]))\n",
        "xgb_multi = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6,\n",
        "                             random_state=42, eval_metric='mlogloss', use_label_encoder=False)\n",
        "\n",
        "binary_results.append(evaluate_model(xgb_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"XGBoost\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(xgb_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"XGBoost\"))\n",
        "\n",
        "# 7. SUPPORT VECTOR MACHINE\n",
        "print(\"7. Training SVM...\")\n",
        "svm_bin = SVC(probability=True, random_state=42, class_weight='balanced')\n",
        "svm_multi = SVC(probability=True, random_state=42, class_weight='balanced', decision_function_shape='ovr')\n",
        "\n",
        "binary_results.append(evaluate_model(svm_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"SVM\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(svm_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"SVM\"))\n",
        "\n",
        "# 8. SIMPLE DNN (Multi-layer Perceptron)\n",
        "print(\"8. Training DNN...\")\n",
        "dnn_bin = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu',\n",
        "                       max_iter=500, random_state=42, early_stopping=True)\n",
        "dnn_multi = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu',\n",
        "                         max_iter=500, random_state=42, early_stopping=True)\n",
        "\n",
        "binary_results.append(evaluate_model(dnn_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"DNN\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(dnn_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"DNN\"))\n",
        "\n",
        "# 9. ENSEMBLE TECHNIQUES\n",
        "print(\"9. Training Ensemble Models...\")\n",
        "\n",
        "# Bagging Ensemble\n",
        "bagging_bin = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=10, class_weight='balanced'),\n",
        "    n_estimators=50,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bagging_multi = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=10, class_weight='balanced'),\n",
        "    n_estimators=50,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(bagging_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Bagging Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(bagging_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Bagging Ensemble\"))\n",
        "\n",
        "# Voting Ensemble\n",
        "voting_bin = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced')),\n",
        "        ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False,\n",
        "                                 scale_pos_weight=len(y_train_bin[y_train_bin==0])/len(y_train_bin[y_train_bin==1]))),\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'))\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_multi = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "        ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False)),\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial'))\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(voting_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Voting Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(voting_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Voting Ensemble\"))\n",
        "\n",
        "# Stacking Ensemble\n",
        "base_estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced')),\n",
        "    ('xgb', xgb.XGBClassifier(n_estimators=50, random_state=42, use_label_encoder=False)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'))\n",
        "]\n",
        "\n",
        "stacking_bin = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_multi = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=LogisticRegression(multi_class='multinomial'),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "binary_results.append(evaluate_model(stacking_bin, X_train_scaled, X_test_scaled,\n",
        "                                    y_train_bin, y_test_bin,\n",
        "                                    multiclass=False, model_name=\"Stacking Ensemble\"))\n",
        "\n",
        "multiclass_results.append(evaluate_model(stacking_multi, X_train_multi_scaled, X_test_multi_scaled,\n",
        "                                        y_train_multi, y_test_multi,\n",
        "                                        multiclass=True, model_name=\"Stacking Ensemble\"))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL EVALUATION RESULTS (WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert results to DataFrames\n",
        "binary_df = pd.DataFrame(binary_results)\n",
        "multiclass_df = pd.DataFrame(multiclass_results)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nBINARY CLASSIFICATION RESULTS (Investment Grade vs Below Investment Grade):\")\n",
        "print(\"-\"*80)\n",
        "display_cols = ['Model', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall',\n",
        "                'F1-Score', 'ROC-AUC', 'Log Loss', 'Misclassification Error']\n",
        "print(binary_df[display_cols].round(4).to_string())\n",
        "\n",
        "print(\"\\n\\nMULTICLASS CLASSIFICATION RESULTS (6 rating categories):\")\n",
        "print(\"-\"*80)\n",
        "print(multiclass_df[display_cols].round(4).to_string())\n",
        "\n",
        "# Display error analysis for binary classification\n",
        "print(\"\\n\\nERROR ANALYSIS FOR BINARY CLASSIFICATION:\")\n",
        "print(\"-\"*80)\n",
        "error_cols = ['Model', 'False Positive', 'False Negative', 'Type I Error',\n",
        "              'Type II Error', 'Total Errors', 'Error Rate', 'Bias Error', 'Variance Error']\n",
        "print(binary_df[error_cols].round(4).to_string())\n",
        "\n",
        "# Rank models by accuracy\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"MODEL RANKING BY ACCURACY (WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nBINARY CLASSIFICATION - Top Models:\")\n",
        "binary_ranked = binary_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "binary_ranked['Rank'] = binary_ranked.index + 1\n",
        "print(binary_ranked[['Rank', 'Model', 'Accuracy', 'F1-Score', 'ROC-AUC']].round(4).head(10).to_string())\n",
        "\n",
        "print(\"\\nMULTICLASS CLASSIFICATION - Top Models:\")\n",
        "multiclass_ranked = multiclass_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "multiclass_ranked['Rank'] = multiclass_ranked.index + 1\n",
        "print(multiclass_ranked[['Rank', 'Model', 'Accuracy', 'F1-Score', 'ROC-AUC']].round(4).head(10).to_string())\n",
        "\n",
        "# Best overall models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST OVERALL MODELS (WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nBEST FOR BINARY CLASSIFICATION:\")\n",
        "best_binary = binary_ranked.iloc[0]\n",
        "print(f\"Model: {best_binary['Model']}\")\n",
        "print(f\"Accuracy: {best_binary['Accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {best_binary['F1-Score']:.4f}\")\n",
        "print(f\"ROC-AUC: {best_binary['ROC-AUC']:.4f}\")\n",
        "print(f\"Log Loss: {best_binary['Log Loss']:.4f}\")\n",
        "\n",
        "print(f\"\\nBEST FOR MULTICLASS CLASSIFICATION:\")\n",
        "best_multi = multiclass_ranked.iloc[0]\n",
        "print(f\"Model: {best_multi['Model']}\")\n",
        "print(f\"Accuracy: {best_multi['Accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {best_multi['F1-Score']:.4f}\")\n",
        "print(f\"ROC-AUC: {best_multi['ROC-AUC']:.4f}\")\n",
        "print(f\"Log Loss: {best_multi['Log Loss']:.4f}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE SUMMARY STATISTICS (WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nBinary Classification - Average Performance:\")\n",
        "binary_avg = binary_df[['Accuracy', 'Balanced Accuracy', 'F1-Score', 'ROC-AUC']].mean()\n",
        "print(binary_avg.round(4).to_string())\n",
        "\n",
        "print(\"\\nMulticlass Classification - Average Performance:\")\n",
        "multi_avg = multiclass_df[['Accuracy', 'Balanced Accuracy', 'F1-Score', 'ROC-AUC']].mean()\n",
        "print(multi_avg.round(4).to_string())\n",
        "\n",
        "# Feature importance for tree-based models\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS (from Random Forest - WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf_model = rf_bin\n",
        "rf_model.fit(X_train_scaled, y_train_bin)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10).round(4).to_string())\n",
        "\n",
        "print(\"\\nFeature Importance Distribution:\")\n",
        "print(f\"Number of features with importance > 0.01: {len(feature_importance[feature_importance['Importance'] > 0.01])}\")\n",
        "print(f\"Number of features with importance > 0.05: {len(feature_importance[feature_importance['Importance'] > 0.05])}\")\n",
        "print(f\"Cumulative importance of top 5 features: {feature_importance['Importance'].head(5).sum():.4f}\")\n",
        "\n",
        "# Additional insights\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS AND RECOMMENDATIONS (WITHOUT TICKER)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. CORRECTED APPROACH - NO DATA LEAKAGE:\")\n",
        "print(\"   - Ticker removed to prevent model memorizing companies\")\n",
        "print(\"   - Models now learn generalizable patterns from financial ratios\")\n",
        "print(\"   - Better generalization to unseen companies\")\n",
        "\n",
        "print(\"\\n2. Best Performing Model Types:\")\n",
        "print(\"   - Ensemble methods (Stacking, Voting, Random Forest) typically perform best\")\n",
        "print(\"   - Gradient boosting (XGBoost) strong for multiclass\")\n",
        "print(\"   - Simpler models (Logistic Regression) provide good baselines\")\n",
        "\n",
        "print(\"\\n3. Error Analysis:\")\n",
        "print(\"   - Type I Errors (False Positives): Classifying risky companies as investment grade\")\n",
        "print(\"   - Type II Errors (False Negatives): Missing investment opportunities\")\n",
        "print(\"   - In financial contexts, Type I errors are often more costly\")\n",
        "\n",
        "print(\"\\n4. Recommendations for Production:\")\n",
        "print(\"   - Use ensemble models for robust performance\")\n",
        "print(\"   - Implement proper cross-validation with company-wise splits if possible\")\n",
        "print(\"   - Consider time-series validation if data has temporal structure\")\n",
        "print(\"   - Monitor for concept drift as financial conditions change\")\n",
        "print(\"   - Use calibrated probability outputs for risk assessment\")\n",
        "\n",
        "print(\"\\n5. Expected Real-World Performance:\")\n",
        "print(\"   - Without ticker leakage, expect lower but more realistic accuracy\")\n",
        "print(\"   - Focus on balanced accuracy and F1-score for imbalanced data\")\n",
        "print(\"   - ROC-AUC provides good measure of overall discriminative power\")\n",
        "\n",
        "# Cross-validation for more robust evaluation\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"CROSS-VALIDATION PERFORMANCE (Top 3 Models)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Select top 3 models for CV\n",
        "top_3_binary_models = [\n",
        "    (binary_ranked.iloc[0]['Model'], eval(f\"{binary_ranked.iloc[0]['Model'].lower().replace(' ', '_')}_bin\")),\n",
        "    (binary_ranked.iloc[1]['Model'], eval(f\"{binary_ranked.iloc[1]['Model'].lower().replace(' ', '_')}_bin\")),\n",
        "    (binary_ranked.iloc[2]['Model'], eval(f\"{binary_ranked.iloc[2]['Model'].lower().replace(' ', '_')}_bin\"))\n",
        "]\n",
        "\n",
        "print(\"\\n5-Fold Cross Validation Scores (Binary):\")\n",
        "for name, model in top_3_binary_models:\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train_bin, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "top_3_multi_models = [\n",
        "    (multiclass_ranked.iloc[0]['Model'], eval(f\"{multiclass_ranked.iloc[0]['Model'].lower().replace(' ', '_')}_multi\")),\n",
        "    (multiclass_ranked.iloc[1]['Model'], eval(f\"{multiclass_ranked.iloc[1]['Model'].lower().replace(' ', '_')}_multi\")),\n",
        "    (multiclass_ranked.iloc[2]['Model'], eval(f\"{multiclass_ranked.iloc[2]['Model'].lower().replace(' ', '_')}_multi\"))\n",
        "]\n",
        "\n",
        "print(\"\\n5-Fold Cross Validation Scores (Multiclass):\")\n",
        "for name, model in top_3_multi_models:\n",
        "    cv_scores = cross_val_score(model, X_train_multi_scaled, y_train_multi, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "are4BSlvjmjU",
        "outputId": "bda23fea-b9d1-47d3-d1b6-9c252a7f87ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CORRECTED data preprocessing (without ticker)...\n",
            "Non-numeric feature columns found: ['Rating_Merged']\n",
            "Column 'Rating_Merged' could not be fully converted to numeric and contains NaNs. Dropping it.\n",
            "Attempted to convert/drop non-numeric columns in features.\n",
            "Features after preprocessing: ['currentRatio', 'quickRatio', 'cashRatio', 'daysOfSalesOutstanding', 'netProfitMargin', 'pretaxProfitMargin', 'grossProfitMargin', 'operatingProfitMargin', 'returnOnAssets', 'returnOnCapitalEmployed', 'returnOnEquity', 'assetTurnover', 'fixedAssetTurnover', 'debtEquityRatio', 'debtRatio', 'effectiveTaxRate', 'freeCashFlowOperatingCashFlowRatio', 'freeCashFlowPerShare', 'cashPerShare', 'companyEquityMultiplier', 'ebitPerRevenue', 'enterpriseValueMultiple', 'operatingCashFlowPerShare', 'operatingCashFlowSalesRatio', 'payablesTurnover', 'Year', 'Month', 'Quarter', 'Sector_Encoded']\n",
            "Number of features: 29\n",
            "Training samples: 1623, Test samples: 406\n",
            "Binary class distribution - Training: [691 932], Test: [173 233]\n",
            "Multiclass distribution - Training: [318  71   6 242 392 537  51   6], Test: [ 80  18   1  60  98 134  13   2]\n",
            "Number of features: 29\n",
            "Preprocessing completed without ticker!\n",
            "\n",
            "Training and evaluating models WITHOUT TICKER...\n",
            "\n",
            "1. Training Logistic Regression...\n",
            "2. Training KNN...\n",
            "3. Training Naive Bayes...\n",
            "4. Training Decision Tree...\n",
            "5. Training Random Forest...\n",
            "6. Training XGBoost...\n",
            "7. Training SVM...\n",
            "8. Training DNN...\n",
            "9. Training Ensemble Models...\n",
            "\n",
            "================================================================================\n",
            "MODEL EVALUATION RESULTS (WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "BINARY CLASSIFICATION RESULTS (Investment Grade vs Below Investment Grade):\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  Accuracy  Balanced Accuracy  Precision  Recall  F1-Score  ROC-AUC  Log Loss  Misclassification Error\n",
            "0   Logistic Regression    0.6601             0.6533     0.7056  0.6996    0.7026   0.7102    0.7978                   0.3399\n",
            "1                   KNN    0.5936             0.5715     0.6269  0.7210    0.6707   0.6239    2.3509                   0.4064\n",
            "2           Naive Bayes    0.6305             0.5680     0.6095  0.9914    0.7549   0.6218   12.5871                   0.3695\n",
            "3         Decision Tree    0.7660             0.7604     0.7949  0.7983    0.7966   0.7267    6.4811                   0.2340\n",
            "4         Random Forest    0.8030             0.7926     0.8072  0.8627    0.8340   0.8879    0.4267                   0.1970\n",
            "5               XGBoost    0.8177             0.8114     0.8326  0.8541    0.8432   0.8924    0.4104                   0.1823\n",
            "6                   SVM    0.6823             0.6569     0.6844  0.8283    0.7495   0.7058    0.6124                   0.3177\n",
            "7                   DNN    0.7069             0.6910     0.7209  0.7983    0.7576   0.7343    0.6900                   0.2931\n",
            "8      Bagging Ensemble    0.8030             0.7926     0.8072  0.8627    0.8340   0.8771    0.4401                   0.1970\n",
            "9       Voting Ensemble    0.8251             0.8149     0.8240  0.8841    0.8530   0.8914    0.4380                   0.1749\n",
            "10    Stacking Ensemble    0.8424             0.8351     0.8477  0.8841    0.8655   0.9042    0.3915                   0.1576\n",
            "\n",
            "\n",
            "MULTICLASS CLASSIFICATION RESULTS (6 rating categories):\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  Accuracy  Balanced Accuracy  Precision  Recall  F1-Score  ROC-AUC  Log Loss  Misclassification Error\n",
            "0   Logistic Regression    0.2143             0.3537     0.1985  0.3537    0.1677   0.6996    1.9858                   0.7857\n",
            "1                   KNN    0.3128             0.1689     0.1672  0.1689    0.1620   0.6416    9.4532                   0.6872\n",
            "2           Naive Bayes    0.0813             0.2572     0.1763  0.2572    0.0682   0.5492   28.5092                   0.9187\n",
            "3         Decision Tree    0.3547             0.3693     0.3498  0.3693    0.3522   0.6495   10.0118                   0.6453\n",
            "4         Random Forest    0.5369             0.4443     0.4832  0.4443    0.4541   0.8518    1.3125                   0.4631\n",
            "5               XGBoost    0.5172             0.4305     0.4986  0.4305    0.4451   0.8514    1.2397                   0.4828\n",
            "6                   SVM    0.2586             0.3845     0.2175  0.3845    0.1989   0.7308    1.5109                   0.7414\n",
            "7                   DNN    0.3695             0.1651     0.1882  0.1651    0.1465   0.7343    1.5230                   0.6305\n",
            "8      Bagging Ensemble    0.5099             0.4361     0.4958  0.4361    0.4447   0.8089    1.3774                   0.4901\n",
            "9       Voting Ensemble    0.5172             0.4095     0.4810  0.4095    0.4201   0.8696    1.2084                   0.4828\n",
            "10    Stacking Ensemble    0.5493             0.3202     0.3469  0.3202    0.3254   0.8804    1.1510                   0.4507\n",
            "\n",
            "\n",
            "ERROR ANALYSIS FOR BINARY CLASSIFICATION:\n",
            "--------------------------------------------------------------------------------\n",
            "                  Model  False Positive  False Negative  Type I Error  Type II Error  Total Errors  Error Rate  Bias Error  Variance Error\n",
            "0   Logistic Regression              68              70            68             70           138      0.3399      0.3475          0.0076\n",
            "1                   KNN             100              65           100             65           165      0.4064      0.2434          0.1630\n",
            "2           Naive Bayes             148               2           148              2           150      0.3695      0.3980          0.0286\n",
            "3         Decision Tree              48              47            48             47            95      0.2340      0.0351          0.1989\n",
            "4         Random Forest              48              32            48             32            80      0.1970      0.0018          0.1952\n",
            "5               XGBoost              40              34            40             34            74      0.1823      0.0000          0.1823\n",
            "6                   SVM              89              40            89             40           129      0.3177      0.3364          0.0187\n",
            "7                   DNN              72              47            72             47           119      0.2931      0.2693          0.0238\n",
            "8      Bagging Ensemble              48              32            48             32            80      0.1970      0.0382          0.1588\n",
            "9       Voting Ensemble              44              27            44             27            71      0.1749      0.0000          0.1749\n",
            "10    Stacking Ensemble              37              27            37             27            64      0.1576      0.0000          0.1576\n",
            "\n",
            "\n",
            "================================================================================\n",
            "MODEL RANKING BY ACCURACY (WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "BINARY CLASSIFICATION - Top Models:\n",
            "   Rank                Model  Accuracy  F1-Score  ROC-AUC\n",
            "0     1    Stacking Ensemble    0.8424    0.8655   0.9042\n",
            "1     2      Voting Ensemble    0.8251    0.8530   0.8914\n",
            "2     3              XGBoost    0.8177    0.8432   0.8924\n",
            "3     4     Bagging Ensemble    0.8030    0.8340   0.8771\n",
            "4     5        Random Forest    0.8030    0.8340   0.8879\n",
            "5     6        Decision Tree    0.7660    0.7966   0.7267\n",
            "6     7                  DNN    0.7069    0.7576   0.7343\n",
            "7     8                  SVM    0.6823    0.7495   0.7058\n",
            "8     9  Logistic Regression    0.6601    0.7026   0.7102\n",
            "9    10          Naive Bayes    0.6305    0.7549   0.6218\n",
            "\n",
            "MULTICLASS CLASSIFICATION - Top Models:\n",
            "   Rank                Model  Accuracy  F1-Score  ROC-AUC\n",
            "0     1    Stacking Ensemble    0.5493    0.3254   0.8804\n",
            "1     2        Random Forest    0.5369    0.4541   0.8518\n",
            "2     3      Voting Ensemble    0.5172    0.4201   0.8696\n",
            "3     4              XGBoost    0.5172    0.4451   0.8514\n",
            "4     5     Bagging Ensemble    0.5099    0.4447   0.8089\n",
            "5     6                  DNN    0.3695    0.1465   0.7343\n",
            "6     7        Decision Tree    0.3547    0.3522   0.6495\n",
            "7     8                  KNN    0.3128    0.1620   0.6416\n",
            "8     9                  SVM    0.2586    0.1989   0.7308\n",
            "9    10  Logistic Regression    0.2143    0.1677   0.6996\n",
            "\n",
            "================================================================================\n",
            "BEST OVERALL MODELS (WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "BEST FOR BINARY CLASSIFICATION:\n",
            "Model: Stacking Ensemble\n",
            "Accuracy: 0.8424\n",
            "F1-Score: 0.8655\n",
            "ROC-AUC: 0.9042\n",
            "Log Loss: 0.3915\n",
            "\n",
            "BEST FOR MULTICLASS CLASSIFICATION:\n",
            "Model: Stacking Ensemble\n",
            "Accuracy: 0.5493\n",
            "F1-Score: 0.3254\n",
            "ROC-AUC: 0.8804\n",
            "Log Loss: 1.1510\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE SUMMARY STATISTICS (WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "Binary Classification - Average Performance:\n",
            "Accuracy             0.7391\n",
            "Balanced Accuracy    0.7225\n",
            "F1-Score             0.7874\n",
            "ROC-AUC              0.7796\n",
            "\n",
            "Multiclass Classification - Average Performance:\n",
            "Accuracy             0.3838\n",
            "Balanced Accuracy    0.3399\n",
            "F1-Score             0.2895\n",
            "ROC-AUC              0.7516\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FEATURE IMPORTANCE ANALYSIS (from Random Forest - WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                        Feature  Importance\n",
            "22    operatingCashFlowPerShare      0.1062\n",
            "8                returnOnAssets      0.0585\n",
            "23  operatingCashFlowSalesRatio      0.0535\n",
            "20               ebitPerRevenue      0.0488\n",
            "9       returnOnCapitalEmployed      0.0477\n",
            "5            pretaxProfitMargin      0.0474\n",
            "4               netProfitMargin      0.0469\n",
            "10               returnOnEquity      0.0460\n",
            "2                     cashRatio      0.0392\n",
            "14                    debtRatio      0.0337\n",
            "\n",
            "Feature Importance Distribution:\n",
            "Number of features with importance > 0.01: 28\n",
            "Number of features with importance > 0.05: 3\n",
            "Cumulative importance of top 5 features: 0.3148\n",
            "\n",
            "================================================================================\n",
            "KEY INSIGHTS AND RECOMMENDATIONS (WITHOUT TICKER)\n",
            "================================================================================\n",
            "\n",
            "1. CORRECTED APPROACH - NO DATA LEAKAGE:\n",
            "   - Ticker removed to prevent model memorizing companies\n",
            "   - Models now learn generalizable patterns from financial ratios\n",
            "   - Better generalization to unseen companies\n",
            "\n",
            "2. Best Performing Model Types:\n",
            "   - Ensemble methods (Stacking, Voting, Random Forest) typically perform best\n",
            "   - Gradient boosting (XGBoost) strong for multiclass\n",
            "   - Simpler models (Logistic Regression) provide good baselines\n",
            "\n",
            "3. Error Analysis:\n",
            "   - Type I Errors (False Positives): Classifying risky companies as investment grade\n",
            "   - Type II Errors (False Negatives): Missing investment opportunities\n",
            "   - In financial contexts, Type I errors are often more costly\n",
            "\n",
            "4. Recommendations for Production:\n",
            "   - Use ensemble models for robust performance\n",
            "   - Implement proper cross-validation with company-wise splits if possible\n",
            "   - Consider time-series validation if data has temporal structure\n",
            "   - Monitor for concept drift as financial conditions change\n",
            "   - Use calibrated probability outputs for risk assessment\n",
            "\n",
            "5. Expected Real-World Performance:\n",
            "   - Without ticker leakage, expect lower but more realistic accuracy\n",
            "   - Focus on balanced accuracy and F1-score for imbalanced data\n",
            "   - ROC-AUC provides good measure of overall discriminative power\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CROSS-VALIDATION PERFORMANCE (Top 3 Models)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'stacking_ensemble_bin' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4047212914.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;31m# Select top 3 models for CV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m top_3_binary_models = [\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mbinary_ranked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{binary_ranked.iloc[0]['Model'].lower().replace(' ', '_')}_bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mbinary_ranked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{binary_ranked.iloc[1]['Model'].lower().replace(' ', '_')}_bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mbinary_ranked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{binary_ranked.iloc[2]['Model'].lower().replace(' ', '_')}_bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stacking_ensemble_bin' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIXED CODE - CORRECTED EVAL FUNCTION ISSUE\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"CROSS-VALIDATION PERFORMANCE (Top 3 Models) - FIXED\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create a mapping of model names to actual model objects for binary classification\n",
        "binary_model_map = {\n",
        "    \"Logistic Regression\": log_reg_bin,\n",
        "    \"KNN\": knn_bin,\n",
        "    \"Naive Bayes\": nb_bin,\n",
        "    \"Decision Tree\": dt_bin,\n",
        "    \"Random Forest\": rf_bin,\n",
        "    \"XGBoost\": xgb_bin,\n",
        "    \"SVM\": svm_bin,\n",
        "    \"DNN\": dnn_bin,\n",
        "    \"Bagging Ensemble\": bagging_bin,\n",
        "    \"Voting Ensemble\": voting_bin,\n",
        "    \"Stacking Ensemble\": stacking_bin\n",
        "}\n",
        "\n",
        "# Create a mapping of model names to actual model objects for multiclass classification\n",
        "multiclass_model_map = {\n",
        "    \"Logistic Regression\": log_reg_multi,\n",
        "    \"KNN\": knn_multi,\n",
        "    \"Naive Bayes\": nb_multi,\n",
        "    \"Decision Tree\": dt_multi,\n",
        "    \"Random Forest\": rf_multi,\n",
        "    \"XGBoost\": xgb_multi,\n",
        "    \"SVM\": svm_multi,\n",
        "    \"DNN\": dnn_multi,\n",
        "    \"Bagging Ensemble\": bagging_multi,\n",
        "    \"Voting Ensemble\": voting_multi,\n",
        "    \"Stacking Ensemble\": stacking_multi\n",
        "}\n",
        "\n",
        "# Select top 3 models for CV using the mapping\n",
        "print(\"\\n5-Fold Cross Validation Scores (Binary):\")\n",
        "for i in range(min(3, len(binary_ranked))):\n",
        "    model_name = binary_ranked.iloc[i]['Model']\n",
        "    model = binary_model_map.get(model_name)\n",
        "    if model is not None:\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train_bin, cv=5, scoring='accuracy')\n",
        "        print(f\"{model_name}: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "    else:\n",
        "        print(f\"Model {model_name} not found in binary_model_map\")\n",
        "\n",
        "print(\"\\n5-Fold Cross Validation Scores (Multiclass):\")\n",
        "for i in range(min(3, len(multiclass_ranked))):\n",
        "    model_name = multiclass_ranked.iloc[i]['Model']\n",
        "    model = multiclass_model_map.get(model_name)\n",
        "    if model is not None:\n",
        "        cv_scores = cross_val_score(model, X_train_multi_scaled, y_train_multi, cv=5, scoring='accuracy')\n",
        "        print(f\"{model_name}: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "    else:\n",
        "        print(f\"Model {model_name} not found in multiclass_model_map\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKZ2Tv1zjtz_",
        "outputId": "c57c5c8c-af4c-4d08-945f-7e7c5077f4e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "CROSS-VALIDATION PERFORMANCE (Top 3 Models) - FIXED\n",
            "================================================================================\n",
            "\n",
            "5-Fold Cross Validation Scores (Binary):\n",
            "Stacking Ensemble: 0.8176 (+/- 0.0482)\n",
            "Voting Ensemble: 0.8219 (+/- 0.0496)\n",
            "XGBoost: 0.8114 (+/- 0.0523)\n",
            "\n",
            "5-Fold Cross Validation Scores (Multiclass):\n",
            "Stacking Ensemble: 0.5367 (+/- 0.0743)\n",
            "Random Forest: 0.5114 (+/- 0.0562)\n",
            "Voting Ensemble: 0.5151 (+/- 0.0819)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_2lFa5Rk9CX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsvWNE6dlW1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8KndpMAlWxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79JkD0CdlWvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Here's a detailed comparison of the accuracy and error metrics for the best-performing models, both with and without the 'Ticker' feature. This will help illustrate the impact of removing the potentially leaky 'Ticker' information.\n",
        "\n",
        "Comparison of Best Models: WITH Ticker vs. WITHOUT Ticker\n",
        "Binary Classification (Investment Grade vs. Below Investment Grade)\n",
        "Metric\tBest Model (WITH Ticker) - XGBoost\tBest Model (WITHOUT Ticker) - Stacking Ensemble\n",
        "Accuracy\t0.8374\t0.8424\n",
        "F1-Score\t0.8625\t0.8655\n",
        "ROC-AUC\t0.8941\t0.9042\n",
        "Log Loss\t0.4115\t0.3915\n",
        "Misclassification Error\t0.1626\t0.1576\n",
        "False Positives\t40\t37\n",
        "False Negatives\t26\t27\n",
        "Total Errors\t66\t64\n",
        "Key Observations (Binary):\n",
        "\n",
        "Interestingly, removing the Ticker feature led to a slight improvement in accuracy, F1-Score, ROC-AUC, and a reduction in total errors for binary classification. The Stacking Ensemble model emerged as the top performer in this scenario.\n",
        "This suggests that the original models, while achieving good scores, might have been overfitting or memorizing aspects related to specific tickers. Without the Ticker, the models are forced to rely purely on financial ratios, leading to more generalized and potentially more robust performance.\n",
        "Multiclass Classification (6 rating categories)\n",
        "Metric\tBest Model (WITH Ticker) - Voting Ensemble\tBest Model (WITHOUT Ticker) - Stacking Ensemble\n",
        "Accuracy\t0.5764\t0.5493\n",
        "F1-Score\t0.4464\t0.3254\n",
        "ROC-AUC\t0.8745\t0.8804\n",
        "Log Loss\t1.1780\t1.1510\n",
        "Misclassification Error\t0.4236\t0.4507\n",
        "Key Observations (Multiclass):\n",
        "\n",
        "For multiclass classification, there is a minor decrease in accuracy when the Ticker feature is removed (from 0.5764 to 0.5493). The F1-Score also saw a more significant drop.\n",
        "However, the ROC-AUC slightly improved (0.8745 to 0.8804), and Log Loss also slightly decreased (1.1780 to 1.1510), indicating that while the models might be slightly less precise in their top-1 prediction (accuracy, F1-score), their probability predictions and overall ability to rank instances correctly across classes improved or remained strong.\n",
        "This outcome is more aligned with expectations: removing a potentially distinguishing feature like Ticker can make the more granular multiclass prediction harder, but the robustness of the probabilistic ranking (ROC-AUC, Log Loss) seems to be maintained or even slightly enhanced due to better generalization.\n",
        "Conclusion: The comparison confirms that removing the Ticker feature leads to a more generalizable model, especially for binary classification, where performance even saw a slight improvement. For multiclass, while top-1 accuracy had a slight dip, other important metrics like ROC-AUC and Log Loss remained strong, suggesting that the models are now learning more robust underlying patterns, which is critical for real-world application where unseen companies will be evaluated. This change successfully addresses the concern of potential data leakage.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "e6xp82julXXF",
        "outputId": "54a76a01-644b-4a76-a25a-e6fa616d1372"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 1) (ipython-input-3205040602.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3205040602.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Here's a detailed comparison of the accuracy and error metrics for the best-performing models, both with and without the 'Ticker' feature. This will help illustrate the impact of removing the potentially leaky 'Ticker' information.\u001b[0m\n\u001b[0m                                                                                                                                                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNBVKoizmtAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}